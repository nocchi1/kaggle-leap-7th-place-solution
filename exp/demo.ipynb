{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import gc\n",
    "import pickle\n",
    "from pathlib import Path, PosixPath\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "from src.utils import seed_everything, get_logger, get_config, TimeUtil\n",
    "from src.utils.competition_utils import clipping_input\n",
    "from src.data import DataProvider, FeatureEngineering, Preprocessor, HFPreprocessor\n",
    "from src.train import get_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# コマンドライン引数\n",
    "exp = '146'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ \u001b[32m2024-10-10 14:50:56\u001b[0m | \u001b[1mINFO ] exp: 146 | run_mode=hf, multi_task=False, loss_type=mae\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "config = get_config(exp, config_dir=Path('../config'))\n",
    "logger = get_logger(config.output_path)\n",
    "logger.info(f'exp: {exp} | run_mode={config.run_mode}, multi_task={config.multi_task}, loss_type={config.loss_type}')\n",
    "\n",
    "seed_everything(config.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "config.run_mode = 'dev'\n",
    "config.multi_task = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Data Loading...] start [0.5GB(4.2%)]\n"
     ]
    }
   ],
   "source": [
    "with TimeUtil.timer('Data Loading...'):\n",
    "    dpr = DataProvider(config)\n",
    "    train_df, test_df = dpr.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Feature Engineering...] start [66.5GB(38.1%)]\n",
      "[Feature Engineering...] done [69.4GB(30.2%)(+2.975GB)] 27.8554 s\n"
     ]
    }
   ],
   "source": [
    "with TimeUtil.timer('Feature Engineering...'):\n",
    "    fer = FeatureEngineering(config)\n",
    "    train_df = fer.feature_engineering(train_df)\n",
    "    test_df = fer.feature_engineering(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Scaling and Clipping Features...] start [69.4GB(30.2%)]\n",
      "[Scaling and Clipping Features...] done [34.4GB(22.5%)(-35.001GB)] 36.5791 s\n"
     ]
    }
   ],
   "source": [
    "with TimeUtil.timer('Scaling and Clipping Features...'):\n",
    "    ppr = Preprocessor(config)\n",
    "    train_df, test_df = ppr.scaling(train_df, test_df)\n",
    "    input_cols, target_cols = ppr.input_cols, ppr.target_cols\n",
    "    if config.task_type == 'grid_pred':\n",
    "        train_df = train_df.drop(target_cols)\n",
    "\n",
    "    valid_df = train_df.filter(pl.col('fold') == 0)\n",
    "    train_df = train_df.filter(pl.col('fold') != 0)\n",
    "    valid_df, input_clip_dict = clipping_input(train_df, valid_df, input_cols)\n",
    "    test_df, _ = clipping_input(None, test_df, input_cols, input_clip_dict)\n",
    "    pickle.dump(input_clip_dict, open(config.output_path / 'input_clip_dict.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Converting to arrays for NN...] start [34.4GB(22.5%)]\n",
      "[Converting to arrays for NN...] done [53.5GB(40.7%)(+19.076GB)] 179.8489 s\n"
     ]
    }
   ],
   "source": [
    "with TimeUtil.timer('Converting to arrays for NN...'):\n",
    "    array_data = ppr.convert_numpy_array(train_df, valid_df, test_df)\n",
    "    del train_df, valid_df, test_df\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare HF Data\n",
    "if config.run_mode == 'hf':\n",
    "    with TimeUtil.timer('HF Data Preprocessing...'):\n",
    "        hf_ppr = HFPreprocessor(config)\n",
    "        # hf_pcr.preprocess_data()\n",
    "        # hf_pcr.convert_numpy_array(near_target=False)\n",
    "        # del train_loader; gc.collect()\n",
    "        # train_loader = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Creating Torch DataLoader...] start [53.5GB(40.7%)]\n",
      "[Creating Torch DataLoader...] done [53.5GB(40.6%)(+0.000GB)] 0.0876 s\n"
     ]
    }
   ],
   "source": [
    "with TimeUtil.timer('Creating Torch DataLoader...'):\n",
    "    train_loader = get_dataloader(\n",
    "        config,\n",
    "        array_data['train_ids'],\n",
    "        array_data['X_train'],\n",
    "        array_data['y_train'],\n",
    "        is_train=True\n",
    "    )\n",
    "    valid_loader = get_dataloader(\n",
    "        config,\n",
    "        array_data['valid_ids'],\n",
    "        array_data['X_valid'],\n",
    "        array_data['y_valid'],\n",
    "        is_train=False\n",
    "    )\n",
    "    test_loader = get_dataloader(\n",
    "        config,\n",
    "        array_data['test_ids'],\n",
    "        array_data['X_test'],\n",
    "        is_train=False\n",
    "    )\n",
    "    del array_data\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from collections import defaultdict\n",
    "from typing import Dict, List, Literal, Tuple\n",
    "\n",
    "import loguru\n",
    "import numpy as np\n",
    "import polars as pl\n",
    "import torch\n",
    "from omegaconf import DictConfig, OmegaConf\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from src.train import ComponentFactory\n",
    "from src.train.train_utils import AverageMeter\n",
    "from src.utils import clean_message\n",
    "from src.utils.competition_utils import evaluate_metric, get_io_columns, get_sub_factor\n",
    "from src.utils.constant import (\n",
    "    PP_TARGET_COLS,\n",
    "    SCALER_TARGET_COLS,\n",
    "    TARGET_MIN_MAX,\n",
    "    VERTICAL_TARGET_COLS,\n",
    ")\n",
    "\n",
    "\n",
    "class Trainer:\n",
    "    def __init__(self, config: DictConfig, logger: loguru._Logger, save_suffix: str = \"\"):\n",
    "        self.config = config\n",
    "        self.eval_step = config.eval_step[config.run_mode]\n",
    "        self.logger = logger\n",
    "        self.save_suffix = save_suffix\n",
    "        self.detail_pbar = True\n",
    "\n",
    "        self.model = ComponentFactory.get_model(config)\n",
    "        self.model = self.model.to(config.device)\n",
    "        n_device = torch.cuda.device_count()\n",
    "        if n_device > 1:\n",
    "            self.model = nn.DataParallel(self.model)\n",
    "        self.loss_fn = ComponentFactory.get_loss(config)\n",
    "        self.train_loss = AverageMeter()\n",
    "        self.valid_loss = AverageMeter()\n",
    "\n",
    "        _, self.target_cols = get_io_columns(config)\n",
    "        self.model_target_cols = self.get_model_target_cols()\n",
    "        self.factor_dict = get_sub_factor(config.input_path, old=False)\n",
    "        self.old_factor_dict = get_sub_factor(config.input_path, old=True)\n",
    "\n",
    "        self.y_numerators = np.load(\n",
    "            config.output_path / f\"y_numerators_{config.target_scale_method}.npy\"\n",
    "        )\n",
    "        self.y_denominators = np.load(\n",
    "            config.output_path / f\"y_denominators_{config.target_scale_method}.npy\"\n",
    "        )\n",
    "        self.target_min_max = [TARGET_MIN_MAX[col] for col in self.target_cols]\n",
    "\n",
    "        self.valid_ids = None\n",
    "        self.test_ids = None\n",
    "        self.valid_pp_df = None\n",
    "        self.test_pp_df = None\n",
    "        self.pp_run = True\n",
    "        self.pp_y_cols = PP_TARGET_COLS\n",
    "        self.pp_x_cols = [col.replace(\"ptend\", \"state\") for col in self.pp_y_cols]\n",
    "\n",
    "        self.best_score_dict = defaultdict(lambda: (-1, -np.inf))\n",
    "\n",
    "    def train(\n",
    "        self,\n",
    "        train_loader: DataLoader,\n",
    "        valid_loader: DataLoader,\n",
    "        colwise_mode: bool = True,\n",
    "        retrain: bool = False,\n",
    "        retrain_weight_name: str = \"\",\n",
    "        retrain_best_score: float = -np.inf,\n",
    "        eval_only: bool = False,\n",
    "    ):\n",
    "        if eval_only:\n",
    "            self.best_score_dict = pickle.load(\n",
    "                open(self.config.output_path / f\"best_score_dict{self.save_suffix}.pkl\", \"rb\")\n",
    "            )\n",
    "            eval_method = \"colwise\" if colwise_mode else \"single\"\n",
    "            score, cw_score, preds, _ = self.valid_evaluate(\n",
    "                valid_loader, current_epoch=-1, eval_count=-1, eval_method=eval_method\n",
    "            )\n",
    "            self.save_oof_df(self.valid_ids, preds)\n",
    "            return score, cw_score, -1\n",
    "\n",
    "        self.optimizer = ComponentFactory.get_optimizer(self.config, self.model)\n",
    "        self.scheduler = ComponentFactory.get_scheduler(\n",
    "            self.config, self.optimizer, steps_per_epoch=len(train_loader)\n",
    "        )\n",
    "        global_step = 0\n",
    "        eval_count = 0\n",
    "        best_score = -np.inf\n",
    "\n",
    "        if retrain:\n",
    "            self.best_score_dict = pickle.load(\n",
    "                open(self.config.output_path / f\"best_score_dict{self.save_suffix}.pkl\", \"rb\")\n",
    "            )\n",
    "            self.model.load_state_dict(\n",
    "                torch.load(self.config.output_path / f\"{retrain_weight_name}.pth\")\n",
    "            )\n",
    "            weight_numbers = [\n",
    "                int(file.stem.split(\"_\")[-1].replace(\"eval\", \"\"))\n",
    "                for file in list(self.config.output_path.glob(f\"model{self.save_suffix}_eval*.pth\"))\n",
    "            ]\n",
    "            eval_count = sorted(weight_numbers)[-1] + 1\n",
    "            best_score = retrain_best_score\n",
    "\n",
    "        # 学習ループの開始\n",
    "        for epoch in tqdm(range(self.config.epochs)):\n",
    "            self.model.train()\n",
    "            self.train_loss.reset()\n",
    "\n",
    "            iterations = (\n",
    "                tqdm(train_loader, total=len(train_loader)) if self.detail_pbar else train_loader\n",
    "            )\n",
    "            for data in iterations:\n",
    "                _, loss = self.forward_step(data, calc_loss=True)\n",
    "                self.optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "                self.scheduler.step()\n",
    "                self.train_loss.update(loss.item(), n=data[0].size(0))\n",
    "                global_step += 1\n",
    "\n",
    "                if global_step % self.eval_step == 0:\n",
    "                    score, _, preds, update_num = self.valid_evaluate(\n",
    "                        valid_loader,\n",
    "                        current_epoch=epoch,\n",
    "                        eval_count=eval_count,\n",
    "                        eval_method=\"single\",\n",
    "                    )\n",
    "                    if colwise_mode and update_num > 0:\n",
    "                        torch.save(\n",
    "                            self.model.state_dict(),\n",
    "                            self.config.output_path\n",
    "                            / f\"model{self.save_suffix}_eval{eval_count}.pth\",\n",
    "                        )\n",
    "\n",
    "                    if score > best_score:\n",
    "                        best_score = score\n",
    "                        best_preds = preds\n",
    "                        best_epochs = epoch\n",
    "                        torch.save(\n",
    "                            self.model.state_dict(),\n",
    "                            self.config.output_path / f\"model{self.save_suffix}_best.pth\",\n",
    "                        )\n",
    "\n",
    "                    eval_count += 1\n",
    "                    self.model.train()\n",
    "\n",
    "            message = f\"\"\"\n",
    "                [Train] :\n",
    "                    Epoch={epoch},\n",
    "                    Loss={self.train_loss.avg:.5f},\n",
    "                    LR={self.optimizer.param_groups[0][\"lr\"]:.5e}\n",
    "            \"\"\"\n",
    "            self.logger.info(clean_message(message))\n",
    "\n",
    "        if colwise_mode:\n",
    "            self.remove_unuse_weights()\n",
    "            best_score, best_cw_score, best_preds, _ = self.valid_evaluate(\n",
    "                valid_loader, current_epoch=-1, eval_count=-1, eval_method=\"colwise\"\n",
    "            )\n",
    "\n",
    "        self.save_oof_df(self.valid_ids, best_preds)\n",
    "        return best_score, best_cw_score, best_epochs\n",
    "\n",
    "    def valid_evaluate(\n",
    "        self,\n",
    "        valid_loader: DataLoader,\n",
    "        current_epoch: int,\n",
    "        eval_count: int,\n",
    "        eval_method: Literal[\"single\", \"colwise\"] = \"single\",\n",
    "    ):\n",
    "        if self.valid_ids is None:\n",
    "            self.valid_ids = valid_loader.dataset.ids\n",
    "\n",
    "        if eval_method == \"single\":\n",
    "            load_best_weight = True if eval_count == -1 else False\n",
    "            preds = self.inference_loop(\n",
    "                valid_loader, mode=\"valid\", load_best_weight=load_best_weight\n",
    "            )\n",
    "        elif eval_method == \"colwise\":\n",
    "            preds = self.inference_loop_colwise(valid_loader, \"valid\", self.best_score_dict)\n",
    "\n",
    "        labels = valid_loader.dataset.y\n",
    "        if self.config.target_shape == \"3dim\":\n",
    "            labels = self.convert_target_3dim_to_2dim(labels)\n",
    "        preds = self.restore_pred(preds)\n",
    "        labels = self.restore_pred(labels)\n",
    "\n",
    "        if self.pp_run and self.valid_pp_df is None:\n",
    "            self.load_postprocess_input(\"valid\")\n",
    "        if self.pp_run:\n",
    "            preds = self.postprocess(preds, run_type=\"valid\")\n",
    "        if self.config.out_clip:\n",
    "            preds = self.clipping_pred(preds)\n",
    "\n",
    "        eval_idx = [\n",
    "            i for i, col in enumerate(self.target_cols) if self.factor_dict[col] != 0\n",
    "        ]  # factor_dictの値が0のものは自動でR2=1になるようにする\n",
    "        score, indiv_scores = evaluate_metric(preds, labels, eval_idx=eval_idx)\n",
    "        cw_score, update_num = self.update_best_score(indiv_scores, eval_count)\n",
    "\n",
    "        message = f\"\"\"\n",
    "            [Valid] :\n",
    "                Epoch={current_epoch},\n",
    "                Loss={self.valid_loss.avg:.5f},\n",
    "                Score={score:.5f},\n",
    "                Best Col-Wise Score={cw_score:.5f}\n",
    "        \"\"\"\n",
    "        self.logger.info(clean_message(message))\n",
    "        return score, cw_score, preds, update_num\n",
    "\n",
    "    def test_predict(\n",
    "        self, test_loader: DataLoader, eval_method: Literal[\"single\", \"colwise\"] = \"single\"\n",
    "    ):\n",
    "        if self.test_ids is None:\n",
    "            self.test_ids = test_loader.dataset.ids\n",
    "\n",
    "        if eval_method == \"single\":\n",
    "            preds = self.inference_loop(test_loader, mode=\"test\", load_best_weight=True)\n",
    "        elif eval_method == \"colwise\":\n",
    "            self.best_score_dict = pickle.load(\n",
    "                open(self.config.output_path / f\"best_score_dict{self.save_suffix}.pkl\", \"rb\")\n",
    "            )\n",
    "            preds = self.inference_loop_colwise(test_loader, \"test\", self.best_score_dict)\n",
    "\n",
    "        preds = self.restore_pred(preds)\n",
    "        if self.pp_run and self.test_pp_df is None:\n",
    "            self.load_postprocess_input(\"test\")\n",
    "        if self.pp_run:\n",
    "            preds = self.postprocess(preds, run_type=\"test\")\n",
    "        if self.config.out_clip:\n",
    "            preds = self.clipping_pred(preds)\n",
    "\n",
    "        pred_df = pl.DataFrame(preds, schema=self.target_cols)\n",
    "        pred_df = pred_df.with_columns(sample_id=pl.Series(self.test_ids))\n",
    "        return pred_df\n",
    "\n",
    "    def inference_loop(\n",
    "        self,\n",
    "        eval_loader: DataLoader,\n",
    "        mode: Literal[\"valid\", \"test\"],\n",
    "        load_best_weight: bool = False,\n",
    "    ):\n",
    "        self.model.eval()\n",
    "        if mode == \"valid\":\n",
    "            self.valid_loss.reset()\n",
    "\n",
    "        # テストデータを推論するときはbest_weightを読み込む\n",
    "        if load_best_weight:\n",
    "            self.model.load_state_dict(\n",
    "                torch.load(self.config.output_path / f\"model{self.save_suffix}_best.pth\")\n",
    "            )\n",
    "\n",
    "        preds = []\n",
    "        with torch.no_grad():\n",
    "            iterations = (\n",
    "                tqdm(eval_loader, total=len(eval_loader)) if self.detail_pbar else eval_loader\n",
    "            )\n",
    "            for data in iterations:\n",
    "                if mode == \"valid\":\n",
    "                    out, loss = self.forward_step(data, calc_loss=True)\n",
    "                    self.valid_loss.update(loss.item(), n=data[0].size(0))\n",
    "                elif mode == \"test\":\n",
    "                    out, _ = self.forward_step(data, calc_loss=False)\n",
    "                preds.append(out.detach().cpu().numpy())\n",
    "        preds = np.concatenate(preds, axis=0)\n",
    "        return preds\n",
    "\n",
    "    def inference_loop_colwise(\n",
    "        self,\n",
    "        test_loader: DataLoader,\n",
    "        mode: Literal[\"valid\", \"test\"],\n",
    "        best_score_dict: dict[str, tuple[int, float]],\n",
    "    ):\n",
    "        self.model.eval()\n",
    "        if mode == \"valid\":\n",
    "            self.valid_loss.reset()\n",
    "\n",
    "        selected_counts = list(set([eval_count for eval_count, _ in best_score_dict.values()]))\n",
    "        all_preds = np.zeros((len(test_loader.dataset), len(self.target_cols)))\n",
    "        for eval_count in tqdm(selected_counts):\n",
    "            self.model.load_state_dict(\n",
    "                torch.load(\n",
    "                    self.config.output_path / f\"model{self.save_suffix}_eval{eval_count}.pth\"\n",
    "                )\n",
    "            )\n",
    "            preds = []\n",
    "            with torch.no_grad():\n",
    "                iterations = (\n",
    "                    tqdm(test_loader, total=len(test_loader)) if self.detail_pbar else test_loader\n",
    "                )\n",
    "                for data in iterations:\n",
    "                    if mode == \"valid\":\n",
    "                        out, loss = self.forward_step(data, calc_loss=True)\n",
    "                        self.valid_loss.update(loss.item(), n=data[0].size(0))\n",
    "                    elif mode == \"test\":\n",
    "                        out, _ = self.forward_step(data, calc_loss=False)\n",
    "                    preds.append(out.detach().cpu().numpy())\n",
    "            preds = np.concatenate(preds, axis=0)\n",
    "\n",
    "            target_cols = [\n",
    "                col for col, (count, _) in best_score_dict.items() if count == eval_count\n",
    "            ]\n",
    "            for col in target_cols:\n",
    "                idx = self.target_cols.index(col)\n",
    "                all_preds[:, idx] = preds[:, idx]\n",
    "        return all_preds\n",
    "\n",
    "    def update_best_score(self, indiv_scores: list[float], eval_count: int):\n",
    "        update_num = 0\n",
    "        for col, score in zip(self.target_cols, indiv_scores):\n",
    "            if score > self.best_score_dict[col][1] and eval_count != -1:\n",
    "                self.best_score_dict[col] = (eval_count, score)\n",
    "                update_num += 1\n",
    "\n",
    "        best_cw_score = (\n",
    "            np.sum([score for _, score in self.best_score_dict.values()])\n",
    "            + (368 - len(self.target_cols))\n",
    "        ) / 368\n",
    "        if update_num > 0 and eval_count != -1:\n",
    "            pickle.dump(\n",
    "                dict(self.best_score_dict),\n",
    "                open(self.config.output_path / f\"best_score_dict{self.save_suffix}.pkl\", \"wb\"),\n",
    "            )\n",
    "        return best_cw_score, update_num\n",
    "\n",
    "    def remove_unuse_weights(self):\n",
    "        selected_counts = set([v[0] for v in self.best_score_dict.values()])\n",
    "        weight_paths = list(self.config.output_path.glob(f\"model{self.save_suffix}_eval*.pth\"))\n",
    "        for path in weight_paths:\n",
    "            eval_count = int(path.stem.split(\"_\")[-1].replace(\"eval\", \"\"))\n",
    "            if eval_count not in selected_counts:\n",
    "                path.unlink()\n",
    "\n",
    "    def forward_step(self, data: torch.Tensor, calc_loss: bool = True):\n",
    "        if calc_loss:\n",
    "            x, y = data\n",
    "            x, y = x.to(self.config.device), y.to(self.config.device)\n",
    "            out = self.model(x)\n",
    "            loss = self.loss_fn(out, y)\n",
    "        else:\n",
    "            x = data[0]\n",
    "            x = x.to(self.config.device)\n",
    "            out = self.model(x)\n",
    "            loss = None\n",
    "\n",
    "        if self.config.target_shape == \"3dim\":\n",
    "            out = self.convert_target_3dim_to_2dim(out)\n",
    "        return out, loss\n",
    "\n",
    "    def convert_target_3dim_to_2dim(\n",
    "        self, y: np.ndarray | torch.Tensor\n",
    "    ) -> np.ndarray | torch.Tensor:\n",
    "        y_v = y[:, :, : len(VERTICAL_TARGET_COLS)]\n",
    "        y_s = y[:, :, len(VERTICAL_TARGET_COLS) :]\n",
    "        if isinstance(y, np.ndarray):\n",
    "            y_v = np.transpose(y_v, (0, 2, 1)).reshape(y.shape[0], -1)\n",
    "            y_s = y_s.mean(axis=1)\n",
    "            y = np.concatenate([y_v, y_s], axis=-1)\n",
    "        elif isinstance(y, torch.Tensor):\n",
    "            y_v = y_v.permute(0, 2, 1).reshape(y.size(0), -1)\n",
    "            y_s = y_s.mean(dim=1)\n",
    "            y = torch.cat([y_v, y_s], dim=-1)\n",
    "        y = self.alignment_target_idx(y)\n",
    "        return y\n",
    "\n",
    "    def alignment_target_idx(self, y: np.ndarray | torch.Tensor) -> np.ndarray | torch.Tensor:\n",
    "        \"\"\"\n",
    "        target_colsとモデルの出力の順番を合わせる\n",
    "        \"\"\"\n",
    "        align_order = [self.model_target_cols.index(col) for col in self.target_cols]\n",
    "        assert len(y.shape) == 2\n",
    "        y = y[:, align_order]\n",
    "        return y\n",
    "\n",
    "    def get_model_target_cols(self):\n",
    "        model_target_cols = []\n",
    "        for col in VERTICAL_TARGET_COLS:\n",
    "            model_target_cols.extend([f\"{col}_{i}\" for i in range(60)])\n",
    "        for col in SCALER_TARGET_COLS:\n",
    "            model_target_cols.append(col)\n",
    "        return model_target_cols\n",
    "\n",
    "    def restore_pred(self, preds: np.ndarray):\n",
    "        return preds * self.y_denominators + self.y_numerators\n",
    "\n",
    "    def clipping_pred(self, preds: np.ndarray):\n",
    "        for i in range(preds.shape[1]):\n",
    "            preds[:, i] = np.clip(preds[:, i], self.target_min_max[i][0], self.target_min_max[i][1])\n",
    "        return preds\n",
    "\n",
    "    def save_oof_df(self, sample_ids: np.ndarray, preds: np.ndarray):\n",
    "        oof_df = pl.DataFrame(preds, schema=self.target_cols)\n",
    "        oof_df = oof_df.with_columns(sample_id=pl.Series(sample_ids))\n",
    "        oof_df.write_parquet(self.config.oof_path / f\"oof{self.save_suffix}.parquet\")\n",
    "\n",
    "    def postprocess(self, preds: np.ndarray, run_type: Literal[\"valid\", \"test\"]):\n",
    "        pp_x = self.valid_pp_df if run_type == \"valid\" else self.test_pp_df\n",
    "        for x_col, y_col in zip(self.pp_x_cols, self.pp_y_cols):\n",
    "            if y_col in self.target_cols:\n",
    "                idx = self.target_cols.index(y_col)\n",
    "                old_factor = self.old_factor_dict[y_col] if self.config.mul_old_factor else 1\n",
    "                preds[:, idx] = (-1 * pp_x[x_col].to_numpy() / 1200) * old_factor\n",
    "        return preds\n",
    "\n",
    "    def load_postprocess_input(self, data_type: Literal[\"valid\", \"test\"]):\n",
    "        if data_type == \"valid\":\n",
    "            valid_path = (\n",
    "                self.config.input_path / \"18_shrinked.parquet\"\n",
    "                if self.config.shared_valid\n",
    "                else self.config.input_path / \"train_shrinked.parquet\"\n",
    "            )\n",
    "            self.valid_pp_df = (\n",
    "                pl.scan_parquet(valid_path)\n",
    "                .select([\"sample_id\"] + self.pp_x_cols)\n",
    "                .filter(pl.col(\"sample_id\").is_in(self.valid_ids))\n",
    "                .collect()\n",
    "            )\n",
    "            id_df = pl.DataFrame({\"sample_id\": self.valid_ids})\n",
    "            self.valid_pp_df = id_df.join(self.valid_pp_df, on=\"sample_id\", how=\"left\")\n",
    "\n",
    "        elif data_type == \"test\":\n",
    "            self.test_pp_df = pl.read_parquet(\n",
    "                self.config.input_path / \"test_shrinked.parquet\",\n",
    "                columns=[\"sample_id\"] + self.pp_x_cols,\n",
    "            )\n",
    "            id_df = pl.DataFrame({\"sample_id\": self.test_ids})\n",
    "            self.test_pp_df = id_df.join(self.test_pp_df, on=\"sample_id\", how=\"left\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(config, logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27 28 0.6665454148778593\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32326/490323976.py:94: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  torch.load(self.config.output_path / f\"{retrain_weight_name}.pth\")\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5c711ffdff347458d1bfd267e6e40a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/240 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "398a841f9ca0471aaa3c2499b851c76a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3375 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a94658a8c2804067a54b50fc0806d625",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/153 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ \u001b[32m2024-10-10 14:24:55\u001b[0m | \u001b[1mINFO ] [Valid] : Epoch=0, Loss=0.16988, Score=0.66968, Best Col-Wise Score=0.67182\u001b[0m\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[99], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m oof_df \u001b[38;5;241m=\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalid_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolwise_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretrain_weight_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmodel_eval27\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretrain_best_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.6665454148778593\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# eval_only=True\u001b[39;49;00m\n\u001b[1;32m      9\u001b[0m \u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[97], line 118\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, train_loader, valid_loader, colwise_mode, retrain, retrain_weight_name, retrain_best_score, eval_only)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscheduler\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m--> 118\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_loss\u001b[38;5;241m.\u001b[39mupdate(\u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m, n\u001b[38;5;241m=\u001b[39mdata[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m))\n\u001b[1;32m    119\u001b[0m global_step \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m global_step \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meval_step \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "oof_df = trainer.train(\n",
    "    train_loader,\n",
    "    valid_loader,\n",
    "    colwise_mode=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6665454148778593"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oof_df[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32326/383357159.py:246: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  torch.load(self.config.output_path / f\"model{self.save_suffix}_best.pth\")\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fc369fc74294b2a81a589c43bd4655b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/153 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pred_df = trainer.test_predict(test_loader, eval_method=\"single\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (625_000, 294)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>ptend_t_0</th><th>ptend_t_1</th><th>ptend_t_2</th><th>ptend_t_3</th><th>ptend_t_4</th><th>ptend_t_5</th><th>ptend_t_6</th><th>ptend_t_7</th><th>ptend_t_8</th><th>ptend_t_9</th><th>ptend_t_10</th><th>ptend_t_11</th><th>ptend_t_12</th><th>ptend_t_13</th><th>ptend_t_14</th><th>ptend_t_15</th><th>ptend_t_16</th><th>ptend_t_17</th><th>ptend_t_18</th><th>ptend_t_19</th><th>ptend_t_20</th><th>ptend_t_21</th><th>ptend_t_22</th><th>ptend_t_23</th><th>ptend_t_24</th><th>ptend_t_25</th><th>ptend_t_26</th><th>ptend_t_27</th><th>ptend_t_28</th><th>ptend_t_29</th><th>ptend_t_30</th><th>ptend_t_31</th><th>ptend_t_32</th><th>ptend_t_33</th><th>ptend_t_34</th><th>ptend_t_35</th><th>ptend_t_36</th><th>&hellip;</th><th>ptend_v_32</th><th>ptend_v_33</th><th>ptend_v_34</th><th>ptend_v_35</th><th>ptend_v_36</th><th>ptend_v_37</th><th>ptend_v_38</th><th>ptend_v_39</th><th>ptend_v_40</th><th>ptend_v_41</th><th>ptend_v_42</th><th>ptend_v_43</th><th>ptend_v_44</th><th>ptend_v_45</th><th>ptend_v_46</th><th>ptend_v_47</th><th>ptend_v_48</th><th>ptend_v_49</th><th>ptend_v_50</th><th>ptend_v_51</th><th>ptend_v_52</th><th>ptend_v_53</th><th>ptend_v_54</th><th>ptend_v_55</th><th>ptend_v_56</th><th>ptend_v_57</th><th>ptend_v_58</th><th>ptend_v_59</th><th>cam_out_NETSW</th><th>cam_out_FLWDS</th><th>cam_out_PRECSC</th><th>cam_out_PRECC</th><th>cam_out_SOLS</th><th>cam_out_SOLL</th><th>cam_out_SOLSD</th><th>cam_out_SOLLD</th><th>sample_id</th></tr><tr><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>&hellip;</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>i32</td></tr></thead><tbody><tr><td>0.072387</td><td>-1.447465</td><td>-1.59126</td><td>-1.238313</td><td>-1.039916</td><td>-0.886447</td><td>-0.759536</td><td>-0.794192</td><td>-0.957017</td><td>-1.032793</td><td>-0.944681</td><td>-0.791783</td><td>-0.54014</td><td>-0.306998</td><td>-0.069964</td><td>0.115484</td><td>0.786033</td><td>0.542847</td><td>0.249372</td><td>-0.374216</td><td>0.418973</td><td>-0.165187</td><td>-0.561241</td><td>-0.873283</td><td>-0.567651</td><td>-0.470924</td><td>-0.43505</td><td>-0.433015</td><td>-0.505128</td><td>-0.621606</td><td>-0.677111</td><td>-0.545636</td><td>-0.367299</td><td>-0.272195</td><td>-0.2401</td><td>-0.230634</td><td>-0.248424</td><td>&hellip;</td><td>0.256084</td><td>-0.121401</td><td>-0.344587</td><td>-0.102638</td><td>-0.091313</td><td>-0.140771</td><td>-0.460923</td><td>-0.049854</td><td>-0.018083</td><td>0.053758</td><td>-0.040552</td><td>0.309686</td><td>0.049827</td><td>0.035883</td><td>-0.286636</td><td>-0.126785</td><td>-1.287177</td><td>-2.573998</td><td>-2.5162</td><td>-1.333147</td><td>1.358848</td><td>1.754033</td><td>1.687201</td><td>0.85524</td><td>0.49837</td><td>0.349224</td><td>0.274072</td><td>0.017806</td><td>0.0</td><td>5.419843</td><td>0.0</td><td>0.06175</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0</td></tr><tr><td>-0.485621</td><td>-1.135914</td><td>-0.649161</td><td>-0.742407</td><td>-0.981201</td><td>-1.199448</td><td>-1.358868</td><td>-1.201348</td><td>-0.899092</td><td>-0.662138</td><td>-0.59916</td><td>-0.602477</td><td>-0.670352</td><td>-0.698934</td><td>-0.682521</td><td>-0.733334</td><td>-0.659958</td><td>-0.355007</td><td>-0.285042</td><td>-0.208013</td><td>-0.244101</td><td>-0.429523</td><td>-0.397009</td><td>-0.343185</td><td>-0.364166</td><td>-0.398045</td><td>-0.450494</td><td>-0.475154</td><td>-0.492672</td><td>-0.480598</td><td>-0.430091</td><td>-0.338034</td><td>-0.181345</td><td>-0.009316</td><td>0.11043</td><td>0.261088</td><td>0.230349</td><td>&hellip;</td><td>-0.090072</td><td>0.020498</td><td>0.086971</td><td>0.050052</td><td>0.027946</td><td>0.063024</td><td>0.045506</td><td>0.026537</td><td>0.026066</td><td>-0.021002</td><td>-0.080584</td><td>-0.01897</td><td>0.002647</td><td>0.106812</td><td>-0.013483</td><td>-0.139997</td><td>-0.227484</td><td>-0.258315</td><td>-0.204068</td><td>-0.163616</td><td>-0.085005</td><td>-0.025923</td><td>-0.004916</td><td>0.093526</td><td>0.099184</td><td>0.026542</td><td>0.081104</td><td>0.141567</td><td>0.0</td><td>4.673466</td><td>0.0</td><td>0.039099</td><td>0.0</td><td>0.0</td><td>0.004282</td><td>0.007173</td><td>10</td></tr><tr><td>-0.234881</td><td>-1.656182</td><td>-0.601238</td><td>-0.433519</td><td>-0.789218</td><td>-0.849147</td><td>-0.75333</td><td>-0.671963</td><td>-0.595635</td><td>-0.537732</td><td>-0.55565</td><td>-0.608882</td><td>-0.711146</td><td>-0.758988</td><td>-0.750639</td><td>-0.721898</td><td>-0.592721</td><td>-0.432625</td><td>-0.277662</td><td>-0.208864</td><td>-0.280137</td><td>-0.387638</td><td>-0.296331</td><td>-0.302601</td><td>-0.214972</td><td>-0.178604</td><td>-0.198711</td><td>-0.220267</td><td>-0.217826</td><td>-0.22134</td><td>-0.288729</td><td>-0.324898</td><td>-0.344786</td><td>-0.334182</td><td>-0.341993</td><td>-0.344061</td><td>-0.341947</td><td>&hellip;</td><td>-0.214113</td><td>-0.028538</td><td>0.044159</td><td>0.040136</td><td>0.044838</td><td>0.076347</td><td>0.07342</td><td>0.041257</td><td>0.025995</td><td>0.00335</td><td>-0.010037</td><td>-0.010856</td><td>0.09887</td><td>0.040718</td><td>-0.088835</td><td>-0.134853</td><td>-0.455447</td><td>-0.750787</td><td>-1.185783</td><td>-1.05277</td><td>0.492555</td><td>0.40803</td><td>0.560029</td><td>0.34848</td><td>0.13647</td><td>0.193376</td><td>0.150923</td><td>0.374985</td><td>0.0</td><td>4.636291</td><td>0.035202</td><td>0.051106</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>100</td></tr><tr><td>0.841697</td><td>0.207503</td><td>0.660262</td><td>0.41642</td><td>-0.099689</td><td>-0.4974</td><td>-0.445526</td><td>-0.274708</td><td>-0.160325</td><td>-0.089188</td><td>-0.028821</td><td>-0.033144</td><td>-0.002816</td><td>0.130474</td><td>0.288755</td><td>0.572247</td><td>0.807359</td><td>0.651383</td><td>0.094121</td><td>0.031484</td><td>-0.032943</td><td>0.033807</td><td>-0.465906</td><td>-0.893544</td><td>-0.641397</td><td>-0.434837</td><td>-0.411204</td><td>-0.475317</td><td>-0.526809</td><td>-0.462754</td><td>-0.374046</td><td>-0.329558</td><td>-0.277853</td><td>-0.227232</td><td>-0.224293</td><td>-0.261834</td><td>-0.335193</td><td>&hellip;</td><td>-0.008861</td><td>0.15785</td><td>-0.316546</td><td>-0.006402</td><td>0.263694</td><td>-0.090587</td><td>0.003734</td><td>-0.151393</td><td>0.007677</td><td>-0.442158</td><td>1.166751</td><td>0.571663</td><td>0.326836</td><td>0.528868</td><td>0.470603</td><td>0.35881</td><td>0.213614</td><td>0.124506</td><td>-0.078239</td><td>-0.124431</td><td>-0.086841</td><td>-0.133892</td><td>-0.240608</td><td>-0.402967</td><td>-0.661201</td><td>-1.068136</td><td>-1.686045</td><td>0.885702</td><td>0.081611</td><td>4.937044</td><td>0.011568</td><td>0.000146</td><td>0.045463</td><td>0.068802</td><td>0.0976</td><td>0.022714</td><td>1000</td></tr><tr><td>1.500539</td><td>0.631652</td><td>0.84002</td><td>1.230621</td><td>1.381638</td><td>1.600752</td><td>1.813521</td><td>1.874617</td><td>1.767358</td><td>1.601102</td><td>1.472667</td><td>1.553341</td><td>1.733075</td><td>1.589896</td><td>1.570783</td><td>1.608648</td><td>1.623847</td><td>1.326061</td><td>0.824457</td><td>0.409224</td><td>0.334102</td><td>0.062525</td><td>-0.189031</td><td>-0.269723</td><td>-0.355983</td><td>-0.37082</td><td>-0.199703</td><td>-0.09418</td><td>-0.072377</td><td>-0.062984</td><td>-0.037737</td><td>-0.056851</td><td>-0.068275</td><td>-0.043301</td><td>0.070918</td><td>0.046332</td><td>0.015303</td><td>&hellip;</td><td>0.007482</td><td>-0.00586</td><td>-0.005332</td><td>0.001344</td><td>0.000645</td><td>-0.007996</td><td>0.004655</td><td>-0.015023</td><td>0.003851</td><td>-0.002278</td><td>-0.006703</td><td>-0.003428</td><td>-0.018436</td><td>-0.000147</td><td>-0.002932</td><td>-0.002815</td><td>0.002792</td><td>-0.002735</td><td>0.004233</td><td>0.015278</td><td>-0.014504</td><td>-0.015983</td><td>-0.016892</td><td>-0.01117</td><td>0.007782</td><td>0.004151</td><td>0.012318</td><td>-0.052589</td><td>3.550347</td><td>5.46045</td><td>0.006965</td><td>0.0</td><td>3.898687</td><td>3.928175</td><td>1.272887</td><td>0.199447</td><td>10000</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>1.555742</td><td>-0.231307</td><td>0.31507</td><td>1.357152</td><td>1.375476</td><td>1.425383</td><td>1.345898</td><td>1.348876</td><td>1.34179</td><td>1.276865</td><td>1.287688</td><td>1.414489</td><td>1.469185</td><td>1.401805</td><td>1.287487</td><td>1.31015</td><td>1.376972</td><td>0.790754</td><td>-0.067635</td><td>0.538727</td><td>0.436302</td><td>0.008843</td><td>-0.175665</td><td>-0.016893</td><td>-0.012854</td><td>-0.127514</td><td>-0.235109</td><td>-0.415306</td><td>-0.446855</td><td>-0.346145</td><td>-0.234438</td><td>-0.26318</td><td>-0.193878</td><td>-0.137943</td><td>-0.12264</td><td>-0.142851</td><td>-0.127268</td><td>&hellip;</td><td>-1.367339</td><td>-1.414375</td><td>-2.515401</td><td>-0.806765</td><td>0.050769</td><td>-0.602515</td><td>-0.922203</td><td>-1.136588</td><td>-1.362953</td><td>-1.078827</td><td>-0.543785</td><td>-1.221819</td><td>-0.858087</td><td>-1.07465</td><td>-0.963729</td><td>0.010406</td><td>0.177658</td><td>0.676587</td><td>2.175902</td><td>2.617899</td><td>1.8335</td><td>1.274838</td><td>0.734899</td><td>0.221132</td><td>0.056085</td><td>-0.055042</td><td>-0.020237</td><td>0.096456</td><td>1.792494</td><td>5.401479</td><td>0.0</td><td>0.206009</td><td>1.71325</td><td>1.731584</td><td>1.342879</td><td>0.859979</td><td>99994</td></tr><tr><td>0.125676</td><td>-1.379655</td><td>-2.742562</td><td>-1.084558</td><td>-0.698364</td><td>-0.503584</td><td>-0.441944</td><td>-0.475176</td><td>-0.569462</td><td>-0.535571</td><td>-0.495798</td><td>-0.482753</td><td>-0.552679</td><td>-0.686463</td><td>-0.874307</td><td>-1.022084</td><td>-1.059304</td><td>-0.9773</td><td>-0.583171</td><td>-0.433945</td><td>-0.282584</td><td>-0.250732</td><td>-0.193453</td><td>-0.190563</td><td>-0.16169</td><td>-0.125672</td><td>-0.121418</td><td>-0.116236</td><td>-0.111314</td><td>-0.09722</td><td>-0.095947</td><td>-0.095008</td><td>-0.091815</td><td>-0.10781</td><td>-0.100974</td><td>-0.112554</td><td>-0.124686</td><td>&hellip;</td><td>-0.001767</td><td>-0.005422</td><td>-0.004283</td><td>-0.001575</td><td>-0.002043</td><td>-0.005807</td><td>-0.005647</td><td>-0.006422</td><td>-0.006536</td><td>-0.006953</td><td>-0.006118</td><td>0.00739</td><td>-0.006179</td><td>0.00661</td><td>-0.002298</td><td>0.000249</td><td>0.000919</td><td>-0.006099</td><td>-0.008529</td><td>0.006642</td><td>-0.011856</td><td>-0.012575</td><td>-0.016818</td><td>-0.023979</td><td>0.007209</td><td>-0.023306</td><td>0.020196</td><td>-0.071072</td><td>0.007836</td><td>2.042937</td><td>0.443394</td><td>0.02423</td><td>0.006911</td><td>0.02251</td><td>0.00699</td><td>0.0</td><td>99995</td></tr><tr><td>0.955648</td><td>0.108612</td><td>0.245928</td><td>0.292953</td><td>0.357661</td><td>0.491642</td><td>0.48425</td><td>0.453527</td><td>0.421007</td><td>0.352576</td><td>0.29612</td><td>0.254613</td><td>0.269711</td><td>0.341166</td><td>0.443086</td><td>0.490532</td><td>0.475491</td><td>0.151646</td><td>0.142014</td><td>0.029529</td><td>0.00432</td><td>-0.013435</td><td>-0.032033</td><td>-0.051299</td><td>-0.010686</td><td>-0.01092</td><td>-0.012744</td><td>-0.003986</td><td>-0.015199</td><td>-0.012578</td><td>-0.022269</td><td>-0.026731</td><td>-0.034253</td><td>-0.038397</td><td>-0.044256</td><td>-0.050118</td><td>-0.058607</td><td>&hellip;</td><td>-0.003791</td><td>-0.005287</td><td>-0.005374</td><td>-0.003278</td><td>-0.002977</td><td>-0.00763</td><td>-0.006406</td><td>-0.00563</td><td>-0.006016</td><td>-0.007582</td><td>-0.008841</td><td>0.001931</td><td>-0.008538</td><td>0.000548</td><td>-0.003473</td><td>-0.002969</td><td>-0.001571</td><td>-0.005772</td><td>0.000074</td><td>0.000333</td><td>-0.010182</td><td>-0.009303</td><td>-0.002546</td><td>-0.00463</td><td>-0.007142</td><td>-0.009745</td><td>-0.00918</td><td>0.004694</td><td>1.047021</td><td>2.473471</td><td>0.542881</td><td>0.059441</td><td>1.069734</td><td>1.22308</td><td>1.082318</td><td>0.704674</td><td>99996</td></tr><tr><td>-0.589185</td><td>-0.345286</td><td>-0.698004</td><td>-0.778368</td><td>-0.880136</td><td>-0.989507</td><td>-0.938784</td><td>-0.869011</td><td>-0.888787</td><td>-0.958739</td><td>-0.952675</td><td>-0.919699</td><td>-0.800661</td><td>-0.702907</td><td>-0.280697</td><td>0.195618</td><td>0.560036</td><td>0.503415</td><td>0.283352</td><td>0.027114</td><td>-0.317059</td><td>-0.35842</td><td>-0.547165</td><td>-0.717264</td><td>-0.894454</td><td>-0.940556</td><td>-1.024346</td><td>-0.862114</td><td>-0.67173</td><td>-0.507013</td><td>-0.453553</td><td>-0.405618</td><td>-0.385944</td><td>-0.383616</td><td>-0.443181</td><td>-0.412004</td><td>-0.422172</td><td>&hellip;</td><td>-0.091295</td><td>-0.099374</td><td>-0.059406</td><td>-0.045226</td><td>-0.037378</td><td>0.006381</td><td>0.307105</td><td>-0.884168</td><td>-0.738261</td><td>-0.27823</td><td>-0.080536</td><td>0.073662</td><td>0.23916</td><td>0.286868</td><td>0.379763</td><td>0.30674</td><td>0.257128</td><td>0.140809</td><td>0.16433</td><td>0.104309</td><td>0.046667</td><td>0.010246</td><td>-0.004849</td><td>-0.019308</td><td>-0.050999</td><td>-0.07442</td><td>-0.094153</td><td>-0.275987</td><td>0.0</td><td>5.24048</td><td>0.00854</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>99997</td></tr><tr><td>1.085023</td><td>0.581673</td><td>1.360181</td><td>1.18548</td><td>1.078016</td><td>0.823197</td><td>0.606351</td><td>0.650046</td><td>0.644379</td><td>0.573568</td><td>0.579465</td><td>0.59386</td><td>0.657125</td><td>0.687795</td><td>0.70206</td><td>0.640953</td><td>0.473733</td><td>0.189989</td><td>-0.056527</td><td>0.041467</td><td>0.043063</td><td>-0.06369</td><td>-0.05919</td><td>-0.11625</td><td>-0.132538</td><td>-0.204738</td><td>-0.191313</td><td>-0.15081</td><td>-0.131576</td><td>-0.137953</td><td>-0.150807</td><td>-0.165232</td><td>-0.174709</td><td>-0.168455</td><td>-0.188748</td><td>-0.218255</td><td>-0.230414</td><td>&hellip;</td><td>-0.028112</td><td>-0.013134</td><td>-0.001027</td><td>0.00521</td><td>0.00058</td><td>0.004402</td><td>0.005832</td><td>-0.004222</td><td>-0.006488</td><td>-0.010849</td><td>-0.029554</td><td>-0.027296</td><td>-0.184562</td><td>-0.434232</td><td>-0.24135</td><td>-0.219102</td><td>-0.216661</td><td>0.142705</td><td>0.021741</td><td>0.002773</td><td>0.055079</td><td>0.373516</td><td>0.462671</td><td>0.968075</td><td>0.183937</td><td>-0.290722</td><td>-0.143214</td><td>-0.398354</td><td>0.578751</td><td>4.616509</td><td>0.015903</td><td>0.076088</td><td>0.286926</td><td>0.32778</td><td>0.833457</td><td>0.735033</td><td>99998</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (625_000, 294)\n",
       "┌───────────┬───────────┬───────────┬───────────┬───┬───────────┬───────────┬───────────┬──────────┐\n",
       "│ ptend_t_0 ┆ ptend_t_1 ┆ ptend_t_2 ┆ ptend_t_3 ┆ … ┆ cam_out_S ┆ cam_out_S ┆ cam_out_S ┆ sample_i │\n",
       "│ ---       ┆ ---       ┆ ---       ┆ ---       ┆   ┆ OLL       ┆ OLSD      ┆ OLLD      ┆ d        │\n",
       "│ f64       ┆ f64       ┆ f64       ┆ f64       ┆   ┆ ---       ┆ ---       ┆ ---       ┆ ---      │\n",
       "│           ┆           ┆           ┆           ┆   ┆ f64       ┆ f64       ┆ f64       ┆ i32      │\n",
       "╞═══════════╪═══════════╪═══════════╪═══════════╪═══╪═══════════╪═══════════╪═══════════╪══════════╡\n",
       "│ 0.072387  ┆ -1.447465 ┆ -1.59126  ┆ -1.238313 ┆ … ┆ 0.0       ┆ 0.0       ┆ 0.0       ┆ 0        │\n",
       "│ -0.485621 ┆ -1.135914 ┆ -0.649161 ┆ -0.742407 ┆ … ┆ 0.0       ┆ 0.004282  ┆ 0.007173  ┆ 10       │\n",
       "│ -0.234881 ┆ -1.656182 ┆ -0.601238 ┆ -0.433519 ┆ … ┆ 0.0       ┆ 0.0       ┆ 0.0       ┆ 100      │\n",
       "│ 0.841697  ┆ 0.207503  ┆ 0.660262  ┆ 0.41642   ┆ … ┆ 0.068802  ┆ 0.0976    ┆ 0.022714  ┆ 1000     │\n",
       "│ 1.500539  ┆ 0.631652  ┆ 0.84002   ┆ 1.230621  ┆ … ┆ 3.928175  ┆ 1.272887  ┆ 0.199447  ┆ 10000    │\n",
       "│ …         ┆ …         ┆ …         ┆ …         ┆ … ┆ …         ┆ …         ┆ …         ┆ …        │\n",
       "│ 1.555742  ┆ -0.231307 ┆ 0.31507   ┆ 1.357152  ┆ … ┆ 1.731584  ┆ 1.342879  ┆ 0.859979  ┆ 99994    │\n",
       "│ 0.125676  ┆ -1.379655 ┆ -2.742562 ┆ -1.084558 ┆ … ┆ 0.02251   ┆ 0.00699   ┆ 0.0       ┆ 99995    │\n",
       "│ 0.955648  ┆ 0.108612  ┆ 0.245928  ┆ 0.292953  ┆ … ┆ 1.22308   ┆ 1.082318  ┆ 0.704674  ┆ 99996    │\n",
       "│ -0.589185 ┆ -0.345286 ┆ -0.698004 ┆ -0.778368 ┆ … ┆ 0.0       ┆ 0.0       ┆ 0.0       ┆ 99997    │\n",
       "│ 1.085023  ┆ 0.581673  ┆ 1.360181  ┆ 1.18548   ┆ … ┆ 0.32778   ┆ 0.833457  ┆ 0.735033  ┆ 99998    │\n",
       "└───────────┴───────────┴───────────┴───────────┴───┴───────────┴───────────┴───────────┴──────────┘"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b13ffcba04f4a9c899b19c9a5e1ffde",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/240 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42227e625a764cd99d45d642a70f1065",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3375 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f997e2f2fd04227bb7ac68125a39821",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/153 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ \u001b[32m2024-10-10 10:07:30\u001b[0m | \u001b[1mINFO ] [Valid] : Epoch=0, Loss=0.28119, Score=0.31449, Best Col-Wise Score=0.31449\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "544480459f8244abbba843b05debbf70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/153 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ \u001b[32m2024-10-10 10:08:49\u001b[0m | \u001b[1mINFO ] [Valid] : Epoch=0, Loss=0.26269, Score=0.36343, Best Col-Wise Score=0.36363\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e99184196c445d19ec52f4a9cc23e72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/153 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ \u001b[32m2024-10-10 10:10:08\u001b[0m | \u001b[1mINFO ] [Valid] : Epoch=0, Loss=0.25043, Score=0.41416, Best Col-Wise Score=0.41457\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89fea923ebf5479aa7dcc727f8881380",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/153 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ \u001b[32m2024-10-10 10:11:27\u001b[0m | \u001b[1mINFO ] [Valid] : Epoch=0, Loss=0.22722, Score=0.48158, Best Col-Wise Score=0.48226\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc62d0d79f884852887a46fc6f7c54d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/153 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ \u001b[32m2024-10-10 10:12:46\u001b[0m | \u001b[1mINFO ] [Valid] : Epoch=0, Loss=0.21943, Score=0.50966, Best Col-Wise Score=0.51021\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f56c66bb7b48478797ef715068c6fc1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/153 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ \u001b[32m2024-10-10 10:14:04\u001b[0m | \u001b[1mINFO ] [Valid] : Epoch=0, Loss=0.20788, Score=0.55110, Best Col-Wise Score=0.55116\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8d9285b62074d0fa74ca163e1c78b4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/153 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ \u001b[32m2024-10-10 10:15:23\u001b[0m | \u001b[1mINFO ] [Valid] : Epoch=0, Loss=0.20354, Score=0.56777, Best Col-Wise Score=0.56811\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94d5d9dca90c46cdbe6c195dcbfc4ec1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/153 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ \u001b[32m2024-10-10 10:16:42\u001b[0m | \u001b[1mINFO ] [Valid] : Epoch=0, Loss=0.20009, Score=0.58099, Best Col-Wise Score=0.58203\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf4e5edfb5c849f087c6eeee96713276",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/153 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ \u001b[32m2024-10-10 10:18:02\u001b[0m | \u001b[1mINFO ] [Valid] : Epoch=0, Loss=0.19554, Score=0.59370, Best Col-Wise Score=0.59386\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12cc23afccd642c3bede479f243221b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/153 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ \u001b[32m2024-10-10 10:19:21\u001b[0m | \u001b[1mINFO ] [Valid] : Epoch=0, Loss=0.19324, Score=0.59970, Best Col-Wise Score=0.60087\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9839713a39904fd5968dabafc223bf41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/153 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ \u001b[32m2024-10-10 10:20:40\u001b[0m | \u001b[1mINFO ] [Valid] : Epoch=0, Loss=0.19273, Score=0.60122, Best Col-Wise Score=0.60463\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e1c628729d64099a3bfd17c474ea723",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/153 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ \u001b[32m2024-10-10 10:21:59\u001b[0m | \u001b[1mINFO ] [Valid] : Epoch=0, Loss=0.18903, Score=0.61432, Best Col-Wise Score=0.61505\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "793bf62d47f94d64bff087dbf026d67d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/153 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ \u001b[32m2024-10-10 10:23:18\u001b[0m | \u001b[1mINFO ] [Valid] : Epoch=0, Loss=0.18824, Score=0.61602, Best Col-Wise Score=0.61906\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b683e19b9ad34b76a8678aaa6e3997f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/153 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ \u001b[32m2024-10-10 10:24:38\u001b[0m | \u001b[1mINFO ] [Valid] : Epoch=0, Loss=0.18484, Score=0.62110, Best Col-Wise Score=0.62384\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10e8a71ac62445d0bb7a87c7faeb76c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/153 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ \u001b[32m2024-10-10 10:25:57\u001b[0m | \u001b[1mINFO ] [Valid] : Epoch=0, Loss=0.18413, Score=0.63048, Best Col-Wise Score=0.63128\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9273c0ee81c34b7c9c7af19288b6336f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/153 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ \u001b[32m2024-10-10 10:27:16\u001b[0m | \u001b[1mINFO ] [Valid] : Epoch=0, Loss=0.18317, Score=0.63415, Best Col-Wise Score=0.63609\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9926accbd3d74c3a9eff641dfff3ef2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/153 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ \u001b[32m2024-10-10 10:28:36\u001b[0m | \u001b[1mINFO ] [Valid] : Epoch=0, Loss=0.17991, Score=0.63892, Best Col-Wise Score=0.64082\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "189781411b5c4b0294152e6eaf09a403",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/153 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ \u001b[32m2024-10-10 10:29:55\u001b[0m | \u001b[1mINFO ] [Valid] : Epoch=0, Loss=0.17891, Score=0.63920, Best Col-Wise Score=0.64284\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "523e3986779c456aa18baa1e03e79707",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/153 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ \u001b[32m2024-10-10 10:31:14\u001b[0m | \u001b[1mINFO ] [Valid] : Epoch=0, Loss=0.17844, Score=0.64732, Best Col-Wise Score=0.64767\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1efa63fcec00443ca522dfe7153950bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/153 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ \u001b[32m2024-10-10 10:32:33\u001b[0m | \u001b[1mINFO ] [Valid] : Epoch=0, Loss=0.17695, Score=0.64971, Best Col-Wise Score=0.65146\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ec5ad4599304a56bc41d3d5d1958539",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/153 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ \u001b[32m2024-10-10 10:33:53\u001b[0m | \u001b[1mINFO ] [Valid] : Epoch=0, Loss=0.17680, Score=0.65087, Best Col-Wise Score=0.65314\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "492fc6aaba284d92b86a6363f7a4a48c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/153 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ \u001b[32m2024-10-10 10:35:12\u001b[0m | \u001b[1mINFO ] [Valid] : Epoch=0, Loss=0.17572, Score=0.65483, Best Col-Wise Score=0.65643\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0af2609a47cc46b5ad69180dc07c9db8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/153 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ \u001b[32m2024-10-10 10:36:31\u001b[0m | \u001b[1mINFO ] [Valid] : Epoch=0, Loss=0.17561, Score=0.65641, Best Col-Wise Score=0.65850\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98647856f9074c43a3454d4e35528fda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/153 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ \u001b[32m2024-10-10 10:37:51\u001b[0m | \u001b[1mINFO ] [Valid] : Epoch=0, Loss=0.17379, Score=0.65722, Best Col-Wise Score=0.66052\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "853548f442bf4960ac4a7ceb65a137a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/153 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ \u001b[32m2024-10-10 10:39:10\u001b[0m | \u001b[1mINFO ] [Valid] : Epoch=0, Loss=0.17354, Score=0.66167, Best Col-Wise Score=0.66341\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34843441b63d44328c37d23928fa9596",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/153 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ \u001b[32m2024-10-10 10:40:29\u001b[0m | \u001b[1mINFO ] [Valid] : Epoch=0, Loss=0.17422, Score=0.65987, Best Col-Wise Score=0.66460\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a9a4579e30249f49f16f60b22c51bf8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/153 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ \u001b[32m2024-10-10 10:41:48\u001b[0m | \u001b[1mINFO ] [Valid] : Epoch=0, Loss=0.17202, Score=0.66506, Best Col-Wise Score=0.66720\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08d19b02f656497fa94c64a062d08e1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/153 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ \u001b[32m2024-10-10 10:43:19\u001b[0m | \u001b[1mINFO ] [Valid] : Epoch=0, Loss=0.17192, Score=0.66655, Best Col-Wise Score=0.66900\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ee5a42137fd478fb04416bf53a34954",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/153 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[60], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m best_score, best_cw_score, best_epochs \u001b[38;5;241m=\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalid_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolwise_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[1;32m      6\u001b[0m \u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[58], line 121\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, train_loader, valid_loader, colwise_mode, retrain, retrain_weight_name, retrain_best_score, eval_only)\u001b[0m\n\u001b[1;32m    118\u001b[0m global_step \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m global_step \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meval_step \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 121\u001b[0m     score, _, preds, update_num \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalid_evaluate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    122\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalid_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    123\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcurrent_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    124\u001b[0m \u001b[43m        \u001b[49m\u001b[43meval_count\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_count\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    125\u001b[0m \u001b[43m        \u001b[49m\u001b[43meval_method\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msingle\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    126\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    127\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m colwise_mode \u001b[38;5;129;01mand\u001b[39;00m update_num \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    128\u001b[0m         torch\u001b[38;5;241m.\u001b[39msave(\n\u001b[1;32m    129\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mstate_dict(),\n\u001b[1;32m    130\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39moutput_path\n\u001b[1;32m    131\u001b[0m             \u001b[38;5;241m/\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave_suffix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_eval\u001b[39m\u001b[38;5;132;01m{\u001b[39;00meval_count\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.pth\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    132\u001b[0m         )\n",
      "Cell \u001b[0;32mIn[58], line 174\u001b[0m, in \u001b[0;36mTrainer.valid_evaluate\u001b[0;34m(self, valid_loader, current_epoch, eval_count, eval_method)\u001b[0m\n\u001b[1;32m    171\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalid_ids \u001b[38;5;241m=\u001b[39m valid_loader\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39mids\n\u001b[1;32m    173\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m eval_method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msingle\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 174\u001b[0m     preds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minference_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalid_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvalid\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mload_best_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m eval_method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolwise\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    176\u001b[0m     preds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minference_loop_colwise(valid_loader, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalid\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbest_score_dict)\n",
      "Cell \u001b[0;32mIn[58], line 257\u001b[0m, in \u001b[0;36mTrainer.inference_loop\u001b[0;34m(self, eval_loader, mode, load_best_weight)\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalid\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    256\u001b[0m     out, loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforward_step(data, calc_loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m--> 257\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalid_loss\u001b[38;5;241m.\u001b[39mupdate(\u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m, n\u001b[38;5;241m=\u001b[39mdata[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m))\n\u001b[1;32m    258\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    259\u001b[0m     out, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforward_step(data, calc_loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "best_score, best_cw_score, best_epochs = trainer.train(\n",
    "    train_loader,\n",
    "    valid_loader,\n",
    "    colwise_mode=True,\n",
    "    eval_only=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PostProcess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from omegaconf import DictConfig\n",
    "import loguru\n",
    "from typing import Literal\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "from src.utils.competition_utils import get_sub_factor, get_io_columns\n",
    "\n",
    "class PostProcess:\n",
    "    def __init__(self, config: DictConfig, logger: loguru._Logger, additional: bool = True):\n",
    "        self.config = config\n",
    "        self.logger = logger\n",
    "        self.additional = additional\n",
    "\n",
    "        _, self.target_cols = get_io_columns(config)\n",
    "        self.old_factor_dict = get_sub_factor(config.input_path, old=True)\n",
    "        self.sub_cols = pl.read_parquet(config.input_path / 'sample_submission.parquet', n_rows=1).columns\n",
    "\n",
    "        self.pp_x_cols = [f'state_q0002_{i}' for i in range(12, 27)]\n",
    "        self.pp_y_cols = [f'ptend_q0002_{i}' for i in range(12, 27)]\n",
    "        self.valid_pp_df = pl.read_parquet(\n",
    "            config.input_path / '18_shrinked.parquet',\n",
    "            columns=['sample_id'] + self.pp_x_cols\n",
    "        )\n",
    "        self.test_pp_df = pl.read_parquet(\n",
    "            config.input_path / 'test_shrinked.parquet',\n",
    "            columns=['sample_id'] + self.pp_x_cols\n",
    "        )\n",
    "\n",
    "        add_pp_y_cols = (\n",
    "            [f'ptend_q0002_{i}' for i in range(60)] +\n",
    "            [f'ptend_q0003_{i}' for i in range(60)]\n",
    "        )\n",
    "        self.add_pp_y_cols = [col for col in add_pp_y_cols if col in self.target_cols]\n",
    "        self.add_pp_x_cols = [col.replace('ptend', 'state') for col in self.add_pp_y_cols]\n",
    "        self.add_valid_pp_df = pl.read_parquet(\n",
    "            config.input_path / '18_shrinked.parquet',\n",
    "            columns=self.sub_cols + self.add_pp_x_cols\n",
    "        )\n",
    "        self.add_test_pp_df = pl.read_parquet(\n",
    "            config.input_path / 'test_shrinked.parquet',\n",
    "            columns=['sample_id'] + self.add_pp_x_cols\n",
    "        )\n",
    "        self.th_dict = None\n",
    "\n",
    "    def postprocess(self, oof_df: pl.DataFrame, sub_df: pl.DataFrame):\n",
    "        oof_df = self.complement_columns(oof_df)\n",
    "        oof_df = self.reverse_sub_factor(oof_df)\n",
    "        oof_df = self.replace_postprocess(oof_df, 'oof')\n",
    "\n",
    "        sub_df = self.complement_columns(sub_df)\n",
    "        sub_df = self.reverse_sub_factor(sub_df)\n",
    "        sub_df = self.replace_postprocess(sub_df, 'sub')\n",
    "\n",
    "        if self.additional:\n",
    "            oof_df = self.additional_postprocess(oof_df, 'oof')\n",
    "            sub_df = self.additional_postprocess(sub_df, 'sub')\n",
    "\n",
    "        oof_df = self.create_oof_df(oof_df)\n",
    "        sub_df = self.create_sub_df(sub_df)\n",
    "        return oof_df, sub_df\n",
    "\n",
    "    def complement_columns(self, pred_df: pl.DataFrame):\n",
    "        lack_cols = list(set(self.sub_cols) - set(pred_df.columns))\n",
    "        for col in lack_cols:\n",
    "            pred_df = pred_df.with_columns([pl.lit(0).alias(col)])\n",
    "        return pred_df\n",
    "\n",
    "    def reverse_sub_factor(self, pred_df: pl.DataFrame):\n",
    "        if self.config.mul_old_factor:\n",
    "            exprs = []\n",
    "            for col in self.target_cols:\n",
    "                if self.old_factor_dict[col] != 0:\n",
    "                    exprs.append((pl.col(col) / self.old_factor_dict[col]).alias(col))\n",
    "\n",
    "            pred_df = pred_df.with_columns(exprs)\n",
    "        return pred_df\n",
    "\n",
    "    def replace_postprocess(self, pred_df: pl.DataFrame, pred_type: Literal['oof', 'sub']):\n",
    "        pp_df = self.valid_pp_df if pred_type == 'oof' else self.test_pp_df\n",
    "        pred_df = pred_df.join(pp_df, on=['sample_id'], how='left')\n",
    "\n",
    "        exprs = []\n",
    "        for x_col, y_col in zip(self.pp_x_cols, self.pp_y_cols):\n",
    "            exprs.append((-1 * pl.col(x_col) / 1200).alias(y_col))\n",
    "        pred_df = pred_df.with_columns(exprs)\n",
    "        pred_df = pred_df.drop(self.pp_x_cols)\n",
    "        return pred_df\n",
    "\n",
    "    def additional_postprocess(self, pred_df: pl.DataFrame, pred_type: Literal['oof', 'sub']):\n",
    "        pp_df = self.add_valid_pp_df if pred_type == 'oof' else self.add_test_pp_df\n",
    "        pred_df = pred_df.join(pp_df, on=['sample_id'], how='left', suffix='_gt')\n",
    "        exprs = []\n",
    "        for x_col, y_col in zip(self.add_pp_x_cols, self.add_pp_y_cols):\n",
    "            exprs.append((pl.col(x_col) + pl.col(y_col) * 1200).alias(f'{x_col}_next'))\n",
    "        pred_df = pred_df.with_columns(exprs)\n",
    "\n",
    "        if pred_type == 'oof':\n",
    "            self.tuning_threshold(pred_df)\n",
    "\n",
    "        assert self.th_dict is not None # oofから実行する必要がある\n",
    "        exprs = []\n",
    "        for y_col, (best_th, _) in self.th_dict.items():\n",
    "            x_col = y_col.replace('ptend', 'state')\n",
    "            exprs.append(\n",
    "                pl.when(pl.col(f'{x_col}_next') < best_th)\n",
    "                .then(-1 * pl.col(x_col) / 1200)\n",
    "                .otherwise(pl.col(y_col))\n",
    "                .alias(y_col)\n",
    "            )\n",
    "        pred_df = pred_df.with_columns(exprs)\n",
    "\n",
    "        if pred_type == 'oof':\n",
    "            scores = []\n",
    "            for col in self.target_cols:\n",
    "                score = r2_score(pred_df[f'{col}_gt'].to_numpy(), pred_df[col].to_numpy())\n",
    "                scores.append(score)\n",
    "            total_score = (np.sum(scores) + (368 - len(scores))) / 368\n",
    "            self.logger.info(f'After Additional Postprocess: {total_score:.5f}')\n",
    "\n",
    "        drop_cols = (\n",
    "            self.add_pp_x_cols +\n",
    "            [f'{col}_next' for col in self.add_pp_x_cols] +\n",
    "            [col for col in pred_df.columns if '_gt' in col]\n",
    "        )\n",
    "        pred_df = pred_df.drop(drop_cols)\n",
    "        return pred_df\n",
    "\n",
    "    def tuning_threshold(self, pred_df: pl.DataFrame):\n",
    "        iterations = tqdm(zip(self.add_pp_x_cols, self.add_pp_y_cols), total=len(self.add_pp_x_cols))\n",
    "        for x_col, y_col in iterations:\n",
    "            best_score = r2_score(pred_df[f'{y_col}_gt'].to_numpy(), pred_df[y_col].to_numpy())\n",
    "            best_th = None\n",
    "            for th_base in [0, 1e-10, 1e-9, 1e-8, 1e-7, 1e-6, 1e-5]:\n",
    "                for corr in range(1, 10):\n",
    "                    if th_base == 0 and corr >= 2:\n",
    "                        break\n",
    "\n",
    "                    th = th_base * corr\n",
    "                    preds = pred_df.select(\n",
    "                        pl.when(pl.col(f'{x_col}_next') < th)\n",
    "                        .then(-1 * pl.col(x_col) / 1200)\n",
    "                        .otherwise(pl.col(y_col))\n",
    "                    ).to_numpy()\n",
    "\n",
    "                    truths = pred_df[f'{y_col}_label'].to_numpy()\n",
    "                    score = r2_score(truths, preds)\n",
    "                    if score > best_score:\n",
    "                        best_score = score\n",
    "                        best_th = th\n",
    "\n",
    "            if best_th is not None:\n",
    "                self.th_dict[y_col] = (best_th, best_score)\n",
    "\n",
    "\n",
    "    def create_oof_df(self, oof_df: pl.DataFrame):\n",
    "        oof_df = oof_df.select(self.sub_cols)\n",
    "        oof_df.write_parquet(self.config.oof_path / 'oof_pp.parquet')\n",
    "        return oof_df\n",
    "\n",
    "    def create_sub_df(self, sub_df: pl.DataFrame):\n",
    "        sub_df = sub_df.with_columns(sample_id = pl.concat_str([pl.lit('test_'), pl.col('sample_id')]))\n",
    "        sub_df = sub_df.select(self.sub_cols)\n",
    "        sub_df.write_csv(self.config.output_path / 'submission_pp.csv')\n",
    "        return sub_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
