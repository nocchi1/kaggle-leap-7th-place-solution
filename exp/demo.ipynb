{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import gc\n",
    "import pickle\n",
    "from pathlib import Path, PosixPath\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "from src.utils import seed_everything, get_logger, get_config, TimeUtil\n",
    "from src.utils.competition_utils import clipping_input\n",
    "from src.data import DataProvider, FeatureEngineering, Preprocessor, HFPreprocessor\n",
    "from src.train import get_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# コマンドライン引数\n",
    "exp = '147'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ \u001b[32m2024-10-09 09:05:52\u001b[0m | \u001b[1mINFO ] exp: 147 | run_mode=hf, multi_task=False, loss_type=mae\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "config = get_config(exp, config_dir=Path('../config'))\n",
    "logger = get_logger(config.output_path)\n",
    "logger.info(f'exp: {exp} | run_mode={config.run_mode}, multi_task={config.multi_task}, loss_type={config.loss_type}')\n",
    "\n",
    "seed_everything(config.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "config.run_mode = 'debug'\n",
    "config.multi_task = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Data Loading...] start [0.6GB(16.9%)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Data Loading...] done [56.7GB(20.4%)(+56.140GB)] 14.0135 s\n"
     ]
    }
   ],
   "source": [
    "with TimeUtil.timer('Data Loading...'):\n",
    "    dpr = DataProvider(config)\n",
    "    train_df, test_df = dpr.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Feature Engineering...] start [56.7GB(20.2%)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Feature Engineering...] done [58.5GB(19.5%)(+1.793GB)] 7.4156 s\n"
     ]
    }
   ],
   "source": [
    "with TimeUtil.timer('Feature Engineering...'):\n",
    "    fer = FeatureEngineering(config)\n",
    "    train_df = fer.feature_engineering(train_df)\n",
    "    test_df = fer.feature_engineering(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Scaling and Clipping Features...] start [58.5GB(19.5%)]\n",
      "[Scaling and Clipping Features...] done [58.2GB(17.9%)(-0.251GB)] 3.9692 s\n"
     ]
    }
   ],
   "source": [
    "with TimeUtil.timer('Scaling and Clipping Features...'):\n",
    "    ppr = Preprocessor(config)\n",
    "    train_df, test_df = ppr.scaling(train_df, test_df)\n",
    "    input_cols, target_cols = ppr.input_cols, ppr.target_cols\n",
    "    if config.task_type == 'grid_pred':\n",
    "        train_df = train_df.drop(target_cols)\n",
    "\n",
    "    valid_df = train_df.filter(pl.col('fold') == 0)\n",
    "    train_df = train_df.filter(pl.col('fold') != 0)\n",
    "    valid_df, input_clip_dict = clipping_input(train_df, valid_df, input_cols)\n",
    "    test_df, _ = clipping_input(None, test_df, input_cols, input_clip_dict)\n",
    "    pickle.dump(input_clip_dict, open(config.output_path / 'input_clip_dict.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Converting to arrays for NN...] start [58.2GB(17.6%)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Converting to arrays for NN...] done [69.2GB(21.7%)(+10.976GB)] 45.7125 s\n"
     ]
    }
   ],
   "source": [
    "with TimeUtil.timer('Converting to arrays for NN...'):\n",
    "    array_data = ppr.convert_numpy_array(train_df, valid_df, test_df)\n",
    "    del train_df, valid_df, test_df\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare HF Data\n",
    "if config.run_mode == 'hf':\n",
    "    with TimeUtil.timer('HF Data Preprocessing...'):\n",
    "        hf_ppr = HFPreprocessor(config)\n",
    "        # hf_pcr.preprocess_data()\n",
    "        # hf_pcr.convert_numpy_array(near_target=False)\n",
    "        # del train_loader; gc.collect()\n",
    "        # train_loader = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Creating Torch DataLoader...] start [69.2GB(21.5%)]\n",
      "[Creating Torch DataLoader...] done [69.2GB(21.5%)(+0.000GB)] 0.1687 s\n"
     ]
    }
   ],
   "source": [
    "with TimeUtil.timer('Creating Torch DataLoader...'):\n",
    "    train_loader = get_dataloader(\n",
    "        config,\n",
    "        array_data['train_ids'],\n",
    "        array_data['X_train'],\n",
    "        array_data['y_train'],\n",
    "        is_train=True\n",
    "    )\n",
    "    valid_loader = get_dataloader(\n",
    "        config,\n",
    "        array_data['valid_ids'],\n",
    "        array_data['X_valid'],\n",
    "        array_data['y_valid'],\n",
    "        is_train=False\n",
    "    )\n",
    "    test_loader = get_dataloader(\n",
    "        config,\n",
    "        array_data['test_ids'],\n",
    "        array_data['X_test'],\n",
    "        is_train=False\n",
    "    )\n",
    "    del array_data\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1024, 60, 30]), torch.Size([1024, 60, 42]))"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for x, y in train_loader:\n",
    "    break\n",
    "\n",
    "x.size(), y.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ComponentFactory.get_model(config)\n",
    "out = model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1024, 60, 42]), torch.Size([1024, 60, 42]))"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.size(), y.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.L1Loss(reduction='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss_fn = ComponentFactory.get_loss(config)\n",
    "loss = loss_fn(out, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1024, 60, 42])"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = loss[:, :, :14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1024, 360])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_vertical = loss[:, :, :len(VERTICAL_TARGET_COLS)].reshape(loss.size(0), -1)\n",
    "loss_scaler ="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = out.size(0)\n",
    "loss_m_v = loss[:, :, :len(VERTICAL_TARGET_COLS)].reshape(bs, -1)\n",
    "loss_m_s = loss[:, :, len(VERTICAL_TARGET_COLS):config.out_dim].mean(dim=1)\n",
    "loss_s_v = torch.cat(\n",
    "    [\n",
    "        loss[:, :, config.out_dim: config.out_dim + len(VERTICAL_TARGET_COLS)].reshape(bs, -1),\n",
    "        loss[:, :, config.out_dim * 2: config.out_dim * 2 + len(VERTICAL_TARGET_COLS)].reshape(bs, -1),\n",
    "    ],\n",
    "    dim=1\n",
    ")\n",
    "loss_s_s = torch.cat(\n",
    "    [\n",
    "        loss[:, :, config.out_dim + len(VERTICAL_TARGET_COLS): config.out_dim * 2].mean(dim=1),\n",
    "        loss[:, :, config.out_dim * 2 + len(VERTICAL_TARGET_COLS):].mean(dim=1),\n",
    "    ],\n",
    "    dim=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.5224, grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1024, 360]),\n",
       " torch.Size([1024, 8]),\n",
       " torch.Size([1024, 720]),\n",
       " torch.Size([1024, 16]))"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_m_v.shape, loss_m_s.shape, loss_s_v.shape, loss_s_s.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eval_idx = [i for i, col in enumerate(self.target_cols) if self.factor_dict[col] != 0]  # factor_dictの値が0のものは自動でR2=1になるようにする\n",
    "# score, indiv_score = evaluate_metric(preds, labels, individual=True, eval_idx=eval_idx)\n",
    "# save_dict = False if load_best_weight else True # 通常の学習ループの時のみbest_score_dictの保存を行う\n",
    "# colwise_score = self.update_best_score(indiv_score, eval_count, save_dict=save_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_metric(\n",
    "    y_pred: np.ndarray, y_true: np.ndarray, eval_idx: list[int] | None = None\n",
    ") -> float | tuple[float, list[float]]:\n",
    "    target_num = 368\n",
    "    total_score = 0\n",
    "    indiv_scores = []\n",
    "\n",
    "    for i in range(y_pred.shape[1]):\n",
    "        if i not in eval_idx:\n",
    "            total_score += 1\n",
    "            indiv_scores.append(1)\n",
    "        else:\n",
    "            score = r2_score(y_true[:, i], y_pred[:, i], force_finite=True)\n",
    "            total_score += score\n",
    "            indiv_scores.append(score)\n",
    "\n",
    "    eval_num = len(indiv_scores)\n",
    "    # y_pred内に存在しないカラムは1として計算する -> sub_factorが0のカラム, 後処理を適用するカラム\n",
    "    if target_num - eval_num > 0:\n",
    "        total_score = (total_score * eval_num + (target_num - eval_num)) / target_num\n",
    "    return total_score, indiv_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "score_dict = defaultdict(lambda: (-1, -np.inf))\n",
    "score_dict[0][1] < 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# スコア更新する時のupdate_best_scoreにおけるsave_dictを除去した, 一旦\n",
    "# これおそらく上書きされたくない時に上書きさせないオプションを提供していたと思うけど後で確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Literal' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[124], line 13\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtrain\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ComponentFactory\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtrain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtrain_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AverageMeter\n\u001b[0;32m---> 13\u001b[0m \u001b[38;5;28;43;01mclass\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;21;43;01mTrainer\u001b[39;49;00m\u001b[43m:\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mdef\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mDictConfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogger\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mloguru\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_Logger\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\n",
      "Cell \u001b[0;32mIn[124], line 130\u001b[0m, in \u001b[0;36mTrainer\u001b[0;34m()\u001b[0m\n\u001b[1;32m    124\u001b[0m             out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconvert_target_3dim_to_2dim(out)\n\u001b[1;32m    125\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m out, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minference_loop\u001b[39m(\n\u001b[1;32m    128\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    129\u001b[0m     test_loader: DataLoader,\n\u001b[0;32m--> 130\u001b[0m     mode: \u001b[43mLiteral\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalid\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m    131\u001b[0m     load_best_weight: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    132\u001b[0m ):\n\u001b[1;32m    133\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m    134\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalid\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Literal' is not defined"
     ]
    }
   ],
   "source": [
    "import loguru\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from omegaconf import OmegaConf, DictConfig\n",
    "\n",
    "from src.utils import clean_message\n",
    "from src.utils.constant import VERTICAL_TARGET_COLS, SCALER_TARGET_COLS, TARGET_MIN_MAX\n",
    "from src.utils.competition_utils import get_io_columns, evaluate_metric\n",
    "from src.train import ComponentFactory\n",
    "from src.train.train_utils import AverageMeter\n",
    "\n",
    "\n",
    "class Trainer:\n",
    "    def __init__(self, config: DictConfig, logger: loguru._Logger, save_suffix: str = ''):\n",
    "        self.config = config\n",
    "        self.logger = logger\n",
    "        self.save_suffix = save_suffix\n",
    "\n",
    "        self.model = ComponentFactory.get_model(config)\n",
    "        self.model = self.model.to(config.device)\n",
    "        n_device = torch.cuda.device_count()\n",
    "        if n_device > 1:\n",
    "            self.model = nn.DataParallel(self.model)\n",
    "        self.loss_fn = ComponentFactory.get_loss(config)\n",
    "\n",
    "        self.train_loss = AverageMeter()\n",
    "        self.valid_loss = AverageMeter()\n",
    "\n",
    "        _, self.target_cols = get_io_columns(config)\n",
    "        self.model_target_cols = self.get_model_target_cols()\n",
    "\n",
    "        self.y_numerators = pickle.load(open(config.output_path / f'y_numerators_{config.target_scale_method}.npy', 'rb'))\n",
    "        self.y_denominators = pickle.load(open(config.output_path / f'y_denominators_{config.target_scale_method}.npy', 'rb'))\n",
    "        self.target_min_max = [TARGET_MIN_MAX[col] for col in config.target_cols]\n",
    "\n",
    "        self.best_score_dict = defaultdict(lambda: (-1, -np.inf))\n",
    "\n",
    "\n",
    "    def train(\n",
    "        self,\n",
    "        train_loader: DataLoader,\n",
    "        valid_loader: DataLoader,\n",
    "        detail_pbar: bool = True,\n",
    "        colwise_save: bool = True,\n",
    "    ):\n",
    "\n",
    "        self.optimizer = self.factory.get_optimizer()\n",
    "        self.scheduler = self.factory.get_scheduler(steps_per_epoch=len(train_loader))\n",
    "\n",
    "        global_step = 0\n",
    "        eval_count = 0\n",
    "        best_score = -np.inf\n",
    "\n",
    "        for epoch in tqdm(range(self.config.epochs)):\n",
    "            self.model.train()\n",
    "            self.train_loss.reset()\n",
    "\n",
    "            iterations = tqdm(train_loader, total=len(train_loader)) if self.detail_pbar else train_loader\n",
    "            for data in iterations:\n",
    "                _, loss = self.forward_step(data, calc_loss=True)\n",
    "                self.optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "                self.scheduler.step()\n",
    "                self.train_loss.update(loss.item(), n=data[0].size(0))\n",
    "                global_step += 1\n",
    "\n",
    "                if global_step % self.config.eval_step == 0:\n",
    "                    score, _, preds, update_num = self.valid_evaluate(\n",
    "                        valid_loader,\n",
    "                        epoch,\n",
    "                        eval_count,\n",
    "                        eval_method='single'\n",
    "                    )\n",
    "                    if colwise_save and update_num > 0:\n",
    "                        torch.save(self.model.state_dict(), self.output_path / f'model{self.save_suffix}_eval{eval_count}.pth')\n",
    "\n",
    "                    if score > best_score:\n",
    "                        best_score = score\n",
    "                        best_preds = preds\n",
    "                        best_epochs = epoch\n",
    "                        torch.save(self.model.state_dict(), self.output_path / f'model{self.save_suffix}_best.pth')\n",
    "\n",
    "                    eval_count += 1\n",
    "                    self.model.train()\n",
    "\n",
    "            message = f\"\"\"\n",
    "                [Train] :\n",
    "                    Epoch={epoch},\n",
    "                    Loss={self.train_loss.avg:.5f},\n",
    "                    LR={self.optimizer.param_groups[0][\"lr\"]:.5e}\n",
    "            \"\"\"\n",
    "            self.logger.info(clean_message(message))\n",
    "\n",
    "        if colwise_save:\n",
    "            best_score, _, best_preds = self.valid_evaluate(\n",
    "                valid_loader, -1, -1, eval_method='colwise'\n",
    "            )\n",
    "            self.remove_unuse_weights()\n",
    "\n",
    "        self.save_oof_df(best_preds, self.valid_ids, self.target_cols)\n",
    "        return best_score, best_epochs  # 全体スコアが最高の時のEpoch\n",
    "\n",
    "\n",
    "    def valid_evaluate(\n",
    "        self,\n",
    "        valid_loader: DataLoader,\n",
    "        current_epoch: int,\n",
    "        eval_count: int,\n",
    "        eval_method: Literal['single', 'colwise'] = 'single',\n",
    "    ):\n",
    "        if self.valid_ids is None:\n",
    "            self.valid_ids = valid_loader.dataset.sample_ids\n",
    "\n",
    "        if eval_method == 'single':\n",
    "            preds = self.inference_loop(valid_loader, mode='valid', load_best_weight=False)\n",
    "        elif eval_method == 'colwise':\n",
    "            preds = self.inference_loop_colwise(valid_loader, 'valid', self.best_score_dict)\n",
    "\n",
    "        labels = valid_loader.dataset.y\n",
    "        if self.config.target_shape == '3dim':\n",
    "            labels = self.convert_target_3dim_to_2dim(labels)\n",
    "\n",
    "        preds = self.restore_pred(preds)\n",
    "        labels = self.restore_pred(labels)\n",
    "\n",
    "        # if self.pp_run and self.valid_pp_x is None:\n",
    "        #     self.load_input_for_postprocess('valid')\n",
    "        # if self.pp_run:\n",
    "        #     preds = self.postprocess(preds, run_type='valid')\n",
    "        if self.config.out_clip:\n",
    "            preds = self.clipping_pred(preds)\n",
    "\n",
    "        eval_idx = [i for i, col in enumerate(self.target_cols) if self.factor_dict[col] != 0]  # factor_dictの値が0のものは自動でR2=1になるようにする\n",
    "        score, indiv_scores = evaluate_metric(preds, labels, eval_idx=eval_idx)\n",
    "        # save_dict = False if load_best_weight else True # 通常の学習ループの時のみbest_score_dictの保存を行う\n",
    "        cw_score, update_num = self.update_best_score(indiv_scores, eval_count)\n",
    "\n",
    "        message = f\"\"\"\n",
    "            [Valid] :\n",
    "                Epoch={current_epoch},\n",
    "                Loss={self.valid_loss.avg:.5f},\n",
    "                Score={score:.5f},\n",
    "                Best Col-Wise Score={cw_score:.5f}\n",
    "        \"\"\"\n",
    "        self.logger.info(clean_message(message))\n",
    "        return score, cw_score, preds, update_num\n",
    "\n",
    "\n",
    "    def inference_loop(\n",
    "        self,\n",
    "        eval_loader: DataLoader,\n",
    "        mode: Literal['valid', 'test'],\n",
    "        load_best_weight: bool = False\n",
    "    ):\n",
    "        self.model.eval()\n",
    "        if mode == 'valid':\n",
    "            self.valid_loss.reset()\n",
    "\n",
    "        # テストデータを推論するときはbest_weightを読み込む\n",
    "        if load_best_weight:\n",
    "            self.model.load_state_dict(torch.load(self.output_path / f'model{self.save_suffix}_best.pth'))\n",
    "\n",
    "        preds = []\n",
    "        with torch.no_grad():\n",
    "            iterations = tqdm(eval_loader, total=len(eval_loader)) if self.detail_pbar else eval_loader\n",
    "            for data in iterations:\n",
    "                if mode == 'valid':\n",
    "                    out, loss = self.forward_step(data, calc_loss=True)\n",
    "                    self.valid_loss.update(loss.item(), n=data[0].size(0))\n",
    "                elif mode == 'test':\n",
    "                    out, _ = self.forward_step(data, calc_loss=False)\n",
    "                preds.append(out.detach().cpu().numpy())\n",
    "        preds = np.concatenate(preds, axis=0)\n",
    "        return preds\n",
    "\n",
    "    def inference_loop_colwise(\n",
    "        self,\n",
    "        test_loader: DataLoader,\n",
    "        mode: Literal[\"valid\", \"test\"],\n",
    "        best_score_dict: Dict[str, Tuple[int, float]],\n",
    "    ):\n",
    "        self.model.eval()\n",
    "        if mode == \"valid\":\n",
    "            self.valid_loss.reset()\n",
    "\n",
    "        use_evals = list(set([eval_count for _, (eval_count, _) in best_score_dict.items()]))\n",
    "        final_preds = np.zeros((len(test_loader.dataset), len(self.target_cols)))\n",
    "        for eval_count in tqdm(use_evals, desc=\"Inference Col-Wise Weight\"):\n",
    "            self.model.load_state_dict(\n",
    "                torch.load(self.output_path / f\"model{self.save_suffix}_eval{eval_count}.pth\")\n",
    "            )\n",
    "            preds = []\n",
    "            with torch.no_grad():\n",
    "                iterations = (\n",
    "                    tqdm(test_loader, total=len(test_loader)) if self.detail_pbar else test_loader\n",
    "                )\n",
    "                for batched in iterations:\n",
    "                    if mode == \"valid\":\n",
    "                        out, loss = self.forward_step(batched, calc_loss=True)\n",
    "                        self.valid_loss.update(loss.item(), n=batched[0].size(0))\n",
    "                    elif mode == \"test\":\n",
    "                        out, _ = self.forward_step(batched, calc_loss=False)\n",
    "                    preds.append(out.detach().cpu().numpy())\n",
    "            preds = np.concatenate(preds, axis=0)\n",
    "            preds = self.restore_pred(preds)\n",
    "\n",
    "            target_cols = [\n",
    "                col for col, (count, _) in best_score_dict.items() if count == eval_count\n",
    "            ]\n",
    "            for col in target_cols:\n",
    "                idx = self.target_cols.index(col)\n",
    "                final_preds[:, idx] = preds[:, idx]\n",
    "        return final_preds\n",
    "\n",
    "    def update_best_score(self, indiv_scores: List[float], eval_count: int):\n",
    "        update_num = 0\n",
    "        for col, score in zip(self.target_cols, indiv_scores):\n",
    "            if score > self.best_score_dict[col][1]:\n",
    "                self.best_score_dict[col] = (eval_count, score)\n",
    "                update_num += 1\n",
    "\n",
    "        best_cw_score = (np.sum([score for _, score in self.best_score_dict.values()]) + (368 - len(self.target_cols))) / 368\n",
    "        if update_num > 0:\n",
    "            pickle.dump(\n",
    "                self.best_score_dict,\n",
    "                open(self.output_path / f\"best_score_dict{self.save_suffix}.pkl\", \"wb\"),\n",
    "            )\n",
    "        return best_cw_score, update_num\n",
    "\n",
    "    def remove_unuse_weights(self):\n",
    "        use_eval_counts = set([v[0] for v in self.best_score_dict.values()])\n",
    "        weight_paths = list(self.output_path.glob(f\"model{self.save_suffix}_eval*.pth\"))\n",
    "        for path in weight_paths:\n",
    "            eval_count = int(path.stem.split(\"_\")[-1].replace(\"eval\", \"\"))\n",
    "            if eval_count not in use_eval_counts:\n",
    "                path.unlink()\n",
    "\n",
    "    def forward_step(self, data: torch.Tensor, calc_loss: bool = True):\n",
    "        if calc_loss:\n",
    "            x, y = data\n",
    "            x, y = x.to(self.device), y.to(self.device)\n",
    "            out = self.model(x)\n",
    "            loss = self.loss_fn(out, y)\n",
    "        else:\n",
    "            x = data\n",
    "            x = x.to(self.device)\n",
    "            out = self.model(x)\n",
    "            loss = None\n",
    "\n",
    "        if self.config.target_shape == '3dim':\n",
    "            out = self.convert_target_3dim_to_2dim(out)\n",
    "        return out, loss\n",
    "\n",
    "    def convert_target_3dim_to_2dim(self, y: torch.Tensor) -> torch.Tensor:\n",
    "        y_v = y[:, :, :len(VERTICAL_TARGET_COLS)]\n",
    "        y_s = y[:, :, len(VERTICAL_TARGET_COLS):]\n",
    "        y_v = y_v.permute(0, 2, 1).reshape(y.size(0), -1)\n",
    "        y_s = y_s.mean(dim=1)\n",
    "        y = torch.cat([y_v, y_s], dim=-1)\n",
    "        y = self.alignment_target_idx(y)\n",
    "        return y\n",
    "\n",
    "    def alignment_target_idx(self, y: np.ndarray | torch.Tensor) -> np.ndarray | torch.Tensor:\n",
    "        \"\"\"\n",
    "        target_colsとモデルの出力の順番を合わせる\n",
    "        \"\"\"\n",
    "        align_order = [self.model_target_cols.index(col) for col in self.target_cols]\n",
    "        assert len(y.shape) == 2\n",
    "        y = y[:, align_order]\n",
    "        return y\n",
    "\n",
    "    def get_model_target_cols(self):\n",
    "        model_target_cols = []\n",
    "        for col in VERTICAL_TARGET_COLS:\n",
    "            model_target_cols.extend([f'{col}_{i}' for i in range(60)])\n",
    "        for col in SCALER_TARGET_COLS:\n",
    "            model_target_cols.append(col)\n",
    "        return model_target_cols\n",
    "\n",
    "    def restore_pred(self, preds: np.ndarray):\n",
    "        return preds * self.config.y_denominators + self.config.y_numerators\n",
    "\n",
    "    def clipping_pred(self, preds: np.ndarray):\n",
    "        for i in range(preds.shape[1]):\n",
    "            preds[:, i] = np.clip(preds[:, i], self.target_min_max[i][0], self.target_min_max[i][1])\n",
    "        return preds\n",
    "\n",
    "        ########################################\n",
    "        if eval_only:\n",
    "            self.best_score_dict = pickle.load(open(self.output_path / f'best_score_dict{self.save_suffix}.pkl', 'rb'))\n",
    "            score, _, preds = self.valid_evaluate(valid_loader, -1, -1, eval_colwise, load_best_weight=True)\n",
    "            self.save_oof_df(preds, self.valid_ids, self.target_cols)\n",
    "            return score, -1\n",
    "        if retrain:\n",
    "            self.best_score_dict = pickle.load(open(self.output_path / f'best_score_dict{self.save_suffix}.pkl', 'rb'))\n",
    "            self.model.load_state_dict(torch.load(self.output_path / f'{retrain_weight_name}.pth'))\n",
    "\n",
    "        global_step = 0\n",
    "        eval_count = 0 if retrain_eval_count is None else retrain_eval_count + 1\n",
    "        best_score = -np.inf if retrain_best_score is None else retrain_best_score\n",
    "        step_per_epoch = len(train_loader) if self.run_mode != 'hf' else self.config.eval_step\n",
    "        self.init_optimizer_and_scheduler(step_per_epoch=step_per_epoch)\n",
    "        for epoch in tqdm(range(self.config.epochs)):\n",
    "            self.model.train()\n",
    "            self.train_loss.reset()\n",
    "            if self.run_mode == 'hf':\n",
    "                del train_loader; gc.collect()\n",
    "                train_loader = self.get_train_loader_from_hf()\n",
    "\n",
    "            iterations = tqdm(train_loader, total=len(train_loader)) if self.detail_pbar else train_loader\n",
    "            for batched in iterations:\n",
    "                _, loss = self.forward_step(batched, calc_loss=True)\n",
    "                self.optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "                self.scheduler.step()\n",
    "                self.train_loss.update(loss.item(), n=batched[0].size(0))\n",
    "                global_step += 1\n",
    "\n",
    "                if global_step % self.config.eval_step == 0:\n",
    "                    score, _, preds = self.valid_evaluate(valid_loader, epoch, eval_count)\n",
    "                    if colwise_best_weight:\n",
    "                        torch.save(self.model.state_dict(), self.output_path / f'model{self.save_suffix}_eval{eval_count}.pth')\n",
    "                    if score > best_score:\n",
    "                        best_score = score\n",
    "                        best_preds = preds\n",
    "                        best_epochs = epoch\n",
    "                        torch.save(self.model.state_dict(), self.output_path / f'model{self.save_suffix}_best.pth')\n",
    "                    eval_count += 1\n",
    "                    self.model.train()\n",
    "\n",
    "            message = f\"\"\"\n",
    "                [Train] :\n",
    "                    Epoch={epoch},\n",
    "                    Loss={self.train_loss.avg:.7f},\n",
    "                    LR={self.optimizer.param_groups[0][\"lr\"]:.4e}\n",
    "            \"\"\"\n",
    "            self.logger.info(clean_message(message))\n",
    "\n",
    "        pickle.dump(self.best_score_dict, open(self.output_path / f'best_score_dict{self.save_suffix}.pkl', 'wb'))\n",
    "        if colwise_best_weight:\n",
    "            best_score, _, best_preds = self.valid_evaluate(valid_loader, -1, -1, eval_colwise=True, load_best_weight=True)\n",
    "            self.remove_unuse_weights()\n",
    "\n",
    "        self.save_oof_df(best_preds, self.valid_ids, self.target_cols)\n",
    "        return best_score, best_epochs # 全体スコアが最高の時のEpoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    def __init__(\n",
    "        self,\n",
    "        config,\n",
    "        model: nn.Module,\n",
    "        loss_fn: nn.Module | None = None,\n",
    "        save_suffix: str = '',\n",
    "        logger: loguru._Logger | None = None,\n",
    "        detail_pbar: bool = True\n",
    "    ):\n",
    "        self.config = config\n",
    "        self.run_mode = config.run_mode\n",
    "        self.device = config.device\n",
    "        self.input_path = config.input_path\n",
    "        self.output_path = config.output_path\n",
    "        self.oof_path = config.oof_path\n",
    "\n",
    "        self.target_cols = config.target_cols\n",
    "        self.mul_old_factor = config.mul_old_factor\n",
    "        self.target_min_max = [TARGET_MIN_MAX[col] for col in config.target_cols]\n",
    "        self.factor_dict = get_sub_factor(config.input_path, old=False)\n",
    "        self.old_factor_dict = get_sub_factor(config.input_path, old=True)\n",
    "        self.out_clip = config.out_clip\n",
    "\n",
    "        self.model = model\n",
    "        self.model.to(self.device)\n",
    "        self.loss_fn = loss_fn\n",
    "        self.train_loss = AverageMeter()\n",
    "        self.valid_loss = AverageMeter()\n",
    "        self.save_suffix = save_suffix\n",
    "        self.logger = logger\n",
    "        self.detail_pbar = detail_pbar\n",
    "\n",
    "        self.hf_ym_list = []\n",
    "        self.valid_ids = None\n",
    "        self.test_ids = None\n",
    "        self.seq_target_cols = None\n",
    "        self.pp_x_cols = [f'state_q0002_{i}' for i in range(12, 27)]\n",
    "        self.pp_y_cols = [f'ptend_q0002_{i}' for i in range(12, 27)]\n",
    "        self.pp_run = len(set(self.target_cols) & set(self.pp_y_cols)) > 0\n",
    "        self.valid_pp_x = None\n",
    "        self.test_pp_x = None\n",
    "        self.best_score_dict = {}\n",
    "\n",
    "    def init_optimizer_and_scheduler(self, step_per_epoch: int):\n",
    "        optimizer = get_optimizer(\n",
    "            self.model,\n",
    "            method=self.config.optimizer_method,\n",
    "            lr=self.config.lr,\n",
    "            weight_decay=self.config.weight_decay,\n",
    "            betas=self.config.betas\n",
    "        )\n",
    "        if self.config.scheduler_method == 'linear':\n",
    "            total_steps = self.config.epochs * step_per_epoch\n",
    "            scheduler_args = {\n",
    "                'start_factor': self.config.linear_start_factor,\n",
    "                'end_factor': self.config.linear_end_factor,\n",
    "                'total_iters': total_steps * self.config.linear_end_step_ratio,\n",
    "            }\n",
    "        elif self.config.scheduler_method == 'multistep':\n",
    "            scheduler_args = {\n",
    "                'milestones': self.config.multi_milestones,\n",
    "                'gamma': self.config.multi_gamma,\n",
    "            }\n",
    "        elif self.config.scheduler_method == 'cosine':\n",
    "            T_0 = self.config.cosine_t0_epoch * step_per_epoch\n",
    "            scheduler_args = {\n",
    "                'T_0': T_0,\n",
    "                'T_mult': self.config.cosine_t_mult,\n",
    "                'eta_min': self.config.cosine_min_lr,\n",
    "                'warmup_steps': self.config.cosine_warmup_steps,\n",
    "                'gamma': self.config.cosine_gamma\n",
    "            }\n",
    "        scheduler = get_scheduler(\n",
    "            optimizer,\n",
    "            method=self.config.scheduler_method,\n",
    "            scheduler_args=scheduler_args\n",
    "        )\n",
    "        self.optimizer = optimizer\n",
    "        self.scheduler = scheduler\n",
    "\n",
    "    def get_train_loader_from_hf(self, files_per_epoch: int = 5):\n",
    "        npy_path = self.config.input_path / 'huggingface' / 'npy'\n",
    "        if len(self.hf_ym_list) == 0:\n",
    "            npy_files = list(npy_path.glob('X_*.npy'))\n",
    "            self.hf_ym_list = [file.stem.split('_')[1] for file in npy_files]\n",
    "        ym_extract = random.sample(self.hf_ym_list, min(files_per_epoch, len(self.hf_ym_list)))\n",
    "        self.hf_ym_list = [ym for ym in self.hf_ym_list if ym not in ym_extract]\n",
    "        X, y = [], []\n",
    "        for ym in ym_extract:\n",
    "            X.append(np.load(npy_path / f'X_{ym}.npy'))\n",
    "            y.append(np.load(npy_path / f'y_{ym}.npy'))\n",
    "        X = np.concatenate(X, axis=0)\n",
    "        y = np.concatenate(y, axis=0)\n",
    "        train_loader = get_dataloader(self.config, sample_ids=None, X=X, y=y, is_train=True)\n",
    "        del X, y; gc.collect()\n",
    "        return train_loader\n",
    "\n",
    "    def train(\n",
    "        self,\n",
    "        train_loader: DataLoader | None,\n",
    "        valid_loader: DataLoader,\n",
    "        colwise_best_weight: bool = False,\n",
    "        eval_only: bool = False,\n",
    "        eval_colwise: bool = False,\n",
    "        retrain: bool = False,\n",
    "        retrain_weight_name: str | None = None,\n",
    "        retrain_best_score: float | None = None,\n",
    "        retrain_eval_count: int | None = None, # 前回の最終eval_countを指定する\n",
    "    ) -> Tuple[float, int]:\n",
    "\n",
    "        if eval_only:\n",
    "            self.best_score_dict = pickle.load(open(self.output_path / f'best_score_dict{self.save_suffix}.pkl', 'rb'))\n",
    "            score, _, preds = self.valid_evaluate(valid_loader, -1, -1, eval_colwise, load_best_weight=True)\n",
    "            self.save_oof_df(preds, self.valid_ids, self.target_cols)\n",
    "            return score, -1\n",
    "        if retrain:\n",
    "            self.best_score_dict = pickle.load(open(self.output_path / f'best_score_dict{self.save_suffix}.pkl', 'rb'))\n",
    "            self.model.load_state_dict(torch.load(self.output_path / f'{retrain_weight_name}.pth'))\n",
    "\n",
    "        global_step = 0\n",
    "        eval_count = 0 if retrain_eval_count is None else retrain_eval_count + 1\n",
    "        best_score = -np.inf if retrain_best_score is None else retrain_best_score\n",
    "        step_per_epoch = len(train_loader) if self.run_mode != 'hf' else self.config.eval_step\n",
    "        self.init_optimizer_and_scheduler(step_per_epoch=step_per_epoch)\n",
    "        for epoch in tqdm(range(self.config.epochs)):\n",
    "            self.model.train()\n",
    "            self.train_loss.reset()\n",
    "            if self.run_mode == 'hf':\n",
    "                del train_loader; gc.collect()\n",
    "                train_loader = self.get_train_loader_from_hf()\n",
    "\n",
    "            iterations = tqdm(train_loader, total=len(train_loader)) if self.detail_pbar else train_loader\n",
    "            for batched in iterations:\n",
    "                _, loss = self.forward_step(batched, calc_loss=True)\n",
    "                self.optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "                self.scheduler.step()\n",
    "                self.train_loss.update(loss.item(), n=batched[0].size(0))\n",
    "                global_step += 1\n",
    "\n",
    "                if global_step % self.config.eval_step == 0:\n",
    "                    score, _, preds = self.valid_evaluate(valid_loader, epoch, eval_count)\n",
    "                    if colwise_best_weight:\n",
    "                        torch.save(self.model.state_dict(), self.output_path / f'model{self.save_suffix}_eval{eval_count}.pth')\n",
    "                    if score > best_score:\n",
    "                        best_score = score\n",
    "                        best_preds = preds\n",
    "                        best_epochs = epoch\n",
    "                        torch.save(self.model.state_dict(), self.output_path / f'model{self.save_suffix}_best.pth')\n",
    "                    eval_count += 1\n",
    "                    self.model.train()\n",
    "\n",
    "            message = f\"\"\"\n",
    "                [Train] :\n",
    "                    Epoch={epoch},\n",
    "                    Loss={self.train_loss.avg:.7f},\n",
    "                    LR={self.optimizer.param_groups[0][\"lr\"]:.4e}\n",
    "            \"\"\"\n",
    "            self.logger.info(clean_message(message))\n",
    "\n",
    "        pickle.dump(self.best_score_dict, open(self.output_path / f'best_score_dict{self.save_suffix}.pkl', 'wb'))\n",
    "        if colwise_best_weight:\n",
    "            best_score, _, best_preds = self.valid_evaluate(valid_loader, -1, -1, eval_colwise=True, load_best_weight=True)\n",
    "            self.remove_unuse_weights()\n",
    "\n",
    "        self.save_oof_df(best_preds, self.valid_ids, self.target_cols)\n",
    "        return best_score, best_epochs # 全体スコアが最高の時のEpoch\n",
    "\n",
    "    def valid_evaluate(\n",
    "        self,\n",
    "        valid_loader: DataLoader,\n",
    "        current_epoch: int,\n",
    "        eval_count: int,\n",
    "        eval_colwise: bool = False,\n",
    "        load_best_weight: bool = False,\n",
    "    ):\n",
    "        if self.valid_ids is None:\n",
    "            self.valid_ids = valid_loader.dataset.sample_ids\n",
    "\n",
    "        if eval_colwise:\n",
    "            preds = self.inference_loop_colwise(valid_loader, 'valid', self.best_score_dict)\n",
    "        else:\n",
    "            preds = self.inference_loop(valid_loader, 'valid', load_best_weight)\n",
    "\n",
    "        labels = valid_loader.dataset.y\n",
    "        if self.config.target_shape == '3dim':\n",
    "            labels = self.convert_target_3dim_to_2dim(labels)\n",
    "        labels = self.restore_pred(labels)\n",
    "\n",
    "        if self.pp_run and self.valid_pp_x is None:\n",
    "            self.load_input_for_postprocess('valid')\n",
    "        if self.pp_run:\n",
    "            preds = self.postprocess(preds, run_type='valid')\n",
    "        if self.out_clip:\n",
    "            preds = self.clipping_pred(preds)\n",
    "\n",
    "        eval_idx = [i for i, col in enumerate(self.target_cols) if self.factor_dict[col] != 0]  # factor_dictの値が0のものは自動でR2=1になるようにする\n",
    "        score, indiv_score = evaluate_metric(preds, labels, individual=True, eval_idx=eval_idx)\n",
    "        save_dict = False if load_best_weight else True # 通常の学習ループの時のみbest_score_dictの保存を行う\n",
    "        colwise_score = self.update_best_score(indiv_score, eval_count, save_dict=save_dict)\n",
    "        message = f\"\"\"\n",
    "            [Valid] :\n",
    "                Epoch={current_epoch},\n",
    "                Loss={self.valid_loss.avg:.7f},\n",
    "                Score={score:.5f},\n",
    "                Best Col-Wise Score={colwise_score:.5f}\n",
    "        \"\"\"\n",
    "        self.logger.info(clean_message(message))\n",
    "        return score, colwise_score, preds\n",
    "\n",
    "    def test_predict(self, test_loader: DataLoader, eval_colwise: bool = False) -> pl.DataFrame:\n",
    "        if self.test_ids is None:\n",
    "            self.test_ids = test_loader.dataset.sample_ids\n",
    "\n",
    "        if eval_colwise:\n",
    "            self.best_score_dict = pickle.load(open(self.output_path / f'best_score_dict{self.save_suffix}.pkl', 'rb'))\n",
    "            preds = self.inference_loop_colwise(test_loader, 'test', self.best_score_dict)\n",
    "        else:\n",
    "            preds = self.inference_loop(test_loader, 'test', load_best_weight=True)\n",
    "\n",
    "        if self.pp_run and self.test_pp_x is None:\n",
    "            self.load_input_for_postprocess('test')\n",
    "        if self.pp_run:\n",
    "            preds = self.postprocess(preds, run_type='test')\n",
    "        if self.out_clip:\n",
    "            preds = self.clipping_pred(preds)\n",
    "\n",
    "        pred_df = pl.DataFrame(preds, schema=self.target_cols)\n",
    "        pred_df = pred_df.with_columns(sample_id = pl.Series(self.test_ids))\n",
    "        return pred_df\n",
    "\n",
    "    def forward_step(self, batched: torch.Tensor, calc_loss: bool = True):\n",
    "        if calc_loss:\n",
    "            x, y = batched\n",
    "            x, y = x.to(self.device), y.to(self.device)\n",
    "            out = self.model(x)\n",
    "            if self.config.target_shape == '3dim':\n",
    "                out = self.convert_target_3dim_to_2dim(out)\n",
    "                y = self.convert_target_3dim_to_2dim(y)\n",
    "            loss = self.loss_fn(out, y)\n",
    "            return out, loss\n",
    "        else:\n",
    "            x = batched\n",
    "            x = x.to(self.device)\n",
    "            out = self.model(x)\n",
    "            if self.config.target_shape == '3dim':\n",
    "                out = self.convert_target_3dim_to_2dim(out)\n",
    "            return out, None\n",
    "\n",
    "    def inference_loop(\n",
    "        self,\n",
    "        test_loader: DataLoader,\n",
    "        mode: Literal['valid', 'test'],\n",
    "        load_best_weight: bool = False\n",
    "    ):\n",
    "        self.model.eval()\n",
    "        if mode == 'valid':\n",
    "            self.valid_loss.reset()\n",
    "        if load_best_weight:\n",
    "            self.model.load_state_dict(torch.load(self.output_path / f'model{self.save_suffix}_best.pth'))\n",
    "\n",
    "        preds = []\n",
    "        with torch.no_grad():\n",
    "            iterations = tqdm(test_loader, total=len(test_loader)) if self.detail_pbar else test_loader\n",
    "            for batched in iterations:\n",
    "                if mode == 'valid':\n",
    "                    out, loss = self.forward_step(batched, calc_loss=True)\n",
    "                    self.valid_loss.update(loss.item(), n=batched[0].size(0))\n",
    "                elif mode == 'test':\n",
    "                    out, _ = self.forward_step(batched, calc_loss=False)\n",
    "                preds.append(out.detach().cpu().numpy())\n",
    "        preds = np.concatenate(preds, axis=0)\n",
    "        preds = self.restore_pred(preds)\n",
    "        return preds\n",
    "\n",
    "    def inference_loop_colwise(\n",
    "        self,\n",
    "        test_loader: DataLoader,\n",
    "        mode: Literal['valid', 'test'],\n",
    "        best_score_dict: Dict[str, Tuple[int, float]],\n",
    "    ):\n",
    "        self.model.eval()\n",
    "        if mode == 'valid':\n",
    "            self.valid_loss.reset()\n",
    "\n",
    "        use_evals = list(set([eval_count for _, (eval_count, _) in best_score_dict.items()]))\n",
    "        final_preds = np.zeros((len(test_loader.dataset), len(self.target_cols)))\n",
    "        for eval_count in tqdm(use_evals, desc='Inference Col-Wise Weight'):\n",
    "            self.model.load_state_dict(torch.load(self.output_path / f'model{self.save_suffix}_eval{eval_count}.pth'))\n",
    "            preds = []\n",
    "            with torch.no_grad():\n",
    "                iterations = tqdm(test_loader, total=len(test_loader)) if self.detail_pbar else test_loader\n",
    "                for batched in iterations:\n",
    "                    if mode == 'valid':\n",
    "                        out, loss = self.forward_step(batched, calc_loss=True)\n",
    "                        self.valid_loss.update(loss.item(), n=batched[0].size(0))\n",
    "                    elif mode == 'test':\n",
    "                        out, _ = self.forward_step(batched, calc_loss=False)\n",
    "                    preds.append(out.detach().cpu().numpy())\n",
    "            preds = np.concatenate(preds, axis=0)\n",
    "            preds = self.restore_pred(preds)\n",
    "\n",
    "            target_cols = [col for col, (count, _) in best_score_dict.items() if count == eval_count]\n",
    "            for col in target_cols:\n",
    "                idx = self.target_cols.index(col)\n",
    "                final_preds[:, idx] = preds[:, idx]\n",
    "        return final_preds\n",
    "\n",
    "    def update_best_score(self, indiv_score: List[float], eval_count: int, save_dict: bool):\n",
    "        for col, score in zip(self.target_cols, indiv_score):\n",
    "            if col not in self.best_score_dict or score > self.best_score_dict[col][1]:\n",
    "                self.best_score_dict[col] = (eval_count, score)\n",
    "        best_colwise_score = (np.sum([score for _, score in self.best_score_dict.values()]) + (368 - len(self.target_cols))) / 368\n",
    "        if save_dict:\n",
    "            pickle.dump(self.best_score_dict, open(self.output_path / f'best_score_dict{self.save_suffix}.pkl', 'wb'))\n",
    "        return best_colwise_score\n",
    "\n",
    "    def remove_unuse_weights(self):\n",
    "        use_eval_counts = set([v[0] for v in self.best_score_dict.values()])\n",
    "        weight_paths = list(self.output_path.glob(f'model{self.save_suffix}_eval*.pth'))\n",
    "        for path in weight_paths:\n",
    "            eval_count = int(path.stem.split('_')[-1].replace('eval', ''))\n",
    "            if eval_count not in use_eval_counts:\n",
    "                path.unlink()\n",
    "\n",
    "    def convert_target_3dim_to_2dim(self, y: np.ndarray | torch.Tensor) -> np.ndarray | torch.Tensor:\n",
    "        y_v = y[:, :, :len(VERTICAL_TARGET_COLS)]\n",
    "        y_s = y[:, :, len(VERTICAL_TARGET_COLS):]\n",
    "        if type(y) == np.ndarray:\n",
    "            y_v = np.transpose(y_v, (0, 2, 1)).reshape(y.shape[0], -1)\n",
    "            y_s = y_s.mean(axis=1)\n",
    "            y = np.concatenate([y_v, y_s], axis=-1)\n",
    "        else:\n",
    "            y_v = y_v.permute(0, 2, 1).reshape(y.size(0), -1)\n",
    "            y_s = y_s.mean(dim=1)\n",
    "            y = torch.cat([y_v, y_s], dim=-1)\n",
    "        y = self.alignment_target_idx(y)\n",
    "        return y\n",
    "\n",
    "    def alignment_target_idx(self, y: np.ndarray | torch.Tensor) -> np.ndarray | torch.Tensor:\n",
    "        if self.seq_target_cols is None:\n",
    "            seq_target_cols = []\n",
    "            for col in VERTICAL_TARGET_COLS:\n",
    "                seq_target_cols.extend([f'{col}_{i}' for i in range(60)])\n",
    "            for col in SCALER_TARGET_COLS:\n",
    "                seq_target_cols.append(col)\n",
    "            self.seq_target_cols = seq_target_cols\n",
    "        align_order = [self.seq_target_cols.index(col) for col in self.target_cols]\n",
    "        assert len(y.shape) == 2\n",
    "        y = y[:, align_order]\n",
    "        return y\n",
    "\n",
    "    def restore_pred(self, preds: np.ndarray):\n",
    "        return preds * self.config.y_denominators + self.config.y_numerators\n",
    "\n",
    "    def clipping_pred(self, preds: np.ndarray):\n",
    "        for i in range(preds.shape[1]):\n",
    "            preds[:, i] = np.clip(\n",
    "                preds[:, i],\n",
    "                self.target_min_max[i][0],\n",
    "                self.target_min_max[i][1]\n",
    "            )\n",
    "        return preds\n",
    "\n",
    "    def postprocess(self, preds: np.ndarray, run_type: Literal['valid', 'test']):\n",
    "        pp_x = self.valid_pp_x if run_type == 'valid' else self.test_pp_x\n",
    "        for y_col, x_col in zip(self.pp_y_cols, self.pp_x_cols):\n",
    "            if y_col in self.target_cols:\n",
    "                idx = self.target_cols.index(y_col)\n",
    "                old_factor = self.old_factor_dict[y_col] if self.mul_old_factor else 1\n",
    "                preds[:, idx] = (-1 * pp_x[x_col].to_numpy() / 1200) * old_factor\n",
    "        return preds\n",
    "\n",
    "    def load_input_for_postprocess(self, data_type: Literal['valid', 'test']):\n",
    "        if data_type == 'valid':\n",
    "            self.valid_pp_x = (\n",
    "                pl.scan_parquet(self.input_path / 'train_pp.parquet')\n",
    "                .select(['sample_id'] + self.pp_x_cols)\n",
    "                .filter(pl.col('sample_id').is_in(self.valid_ids))\n",
    "                .collect()\n",
    "            )\n",
    "            id_df = pl.DataFrame({'sample_id': self.valid_ids})\n",
    "            self.valid_pp_x = id_df.join(self.valid_pp_x, on='sample_id', how='left')\n",
    "\n",
    "        elif data_type == 'test':\n",
    "            self.test_pp_x = pl.read_parquet(\n",
    "                Config.input_path / 'test_pp.parquet',\n",
    "                columns=['sample_id'] + self.pp_x_cols\n",
    "            )\n",
    "            id_df = pl.DataFrame({'sample_id': self.test_ids})\n",
    "            self.test_pp_x = id_df.join(self.test_pp_x, on='sample_id', how='left')\n",
    "\n",
    "    def save_oof_df(self, preds: np.ndarray, sample_ids: np.ndarray, target_cols: List[str]):\n",
    "        oof_df = pl.DataFrame(preds, schema=target_cols)\n",
    "        oof_df = oof_df.with_columns(sample_id = pl.Series(sample_ids))\n",
    "        oof_df.write_parquet(self.oof_path / f'oof{self.save_suffix}.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "save_suffix = ''\n",
    "trainer = Trainer(config, model, loss_fn, save_suffix=save_suffix, logger=logger)\n",
    "best_score, best_epoch = trainer.train(\n",
    "    train_loader,\n",
    "    valid_loader,\n",
    "    colwise_best_weight=True,\n",
    "    # eval_only=True,\n",
    "    # eval_colwise=True,\n",
    "    retrain=True,\n",
    "    retrain_weight_name='model_eval239',\n",
    "    retrain_best_score=0.78355,\n",
    "    retrain_eval_count=239, # 前回の最終eval_countを指定する\n",
    ")\n",
    "logger.info(f'At Epoch={best_epoch}, Best Score={best_score:.4f}')\n",
    "pred_df = trainer.test_predict(test_loader, eval_colwise=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
