device: 'cuda'
seed: 10


exp: '147'
run_mode: 'full'
task_type: 'main'
mul_old_factor: true
device: 'cuda'
seed: 10

data:
  input_path: '../data/input'
  output_path: '../data/output/147'
  oof_path: '../data/oof/147'

dataset:
  shared_valid: true
  valid_ratio: 0.20
  input_shape: '3dim'
  target_shape: '3dim'
  input_scale_method: 'standard'
  target_scale_method: 'standard_y2'

model:
  model_type: 'transformer'
  in_dim: 86
  out_dim: 14
  hidden_dim: 256
  scaler_num: 16
  trans_num_layers: 4
  lstm_block_num: 2

training:
  loss_type: 'mse'
  train_batch: 1024
  eval_batch: 4096
  out_clip: true
  epochs: 100
  eval_step: 4000

optimizer:
  method: 'adamw'
  lr: 1e-5
  weight_decay: 0.01
  betas: [0.9, 0.999]

scheduler:
  method: 'cosine'
  t0_epoch: 100
  t_mult: 1
  min_lr: 5e-6
  warmup_steps: 200
  gamma: 1.0

class Config:


    # overall
    exp = '147'
    run_mode: Literal['hf', 'full', 'dev', 'debug'] = 'hf'
    task_type: Literal['main', 'grid_pred'] = 'main'
    mul_old_factor = True
    device = 'cuda'
    seed = 10

    # data path
    input_path = Path('../data/input')
    output_path = Path(f'../data/output/{exp}')
    output_path.mkdir(exist_ok=True, parents=True)
    oof_path = Path(f'../data/oof/{exp}')
    oof_path.mkdir(exist_ok=True, parents=True)

    # dataset
    shared_valid = True
    valid_ratio = 0.20
    input_shape = '3dim'
    target_shape = '3dim'
    input_scale_method = 'standard'
    target_scale_method = 'standard_y2'

    # model
    model_type = 'transformer'
    in_dim = 86
    out_dim = 14
    hidden_dim = 256
    scaler_num = 16
    # conv1d
    # block_num = 15
    # kernel_size = 5
    # # transformer
    trans_num_layers = 4
    lstm_block_num = 2
    # # lstm
    # block_num = 6

    # training
    loss_type = 'mse'
    train_batch = 1024
    eval_batch = 4096
    out_clip = True
    epochs = 100
    eval_step = (
        4000 if run_mode in ['hf', 'full'] else
        2000 if run_mode == 'dev' else
        20
    )

    # optimizer
    optimizer_method = 'adamw'
    lr = 1e-5
    weight_decay = 0.01
    betas = (0.9, 0.999)

    # scheduler
    scheduler_method = 'cosine'
    cosine_t0_epoch = epochs # 学習全体で1周するようにする
    cosine_t_mult = 1
    cosine_min_lr = 5e-6
    cosine_warmup_steps = 200
    cosine_gamma = 1.0 # サイクルごとの最大学習率の減衰率
